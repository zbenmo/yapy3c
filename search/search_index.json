{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Yet Another Python3 Course (YAPY3C)","text":"<p>My name is Oren, and I'll be your instructor.</p> <p>You can contact me at 'zbenmo@gmail.com'.</p>"},{"location":"part_I/","title":"Part I","text":"<p>In Part I we learn the basics, data types, and the structure of a program.</p> <p>Let\u2019s get an access to a Python environment. The following should work for you:</p> <p>https://www.python.org/shell/</p> <p>(You are most welcome to use JupyterLab or an editor of your choice and to run your Python scripts with 'python my_script.py', as an example, if you already know your way.)</p> <p>There are a few versions of Python, we\u2019ll use Python 3. Let\u2019s make sure this is what we have. run there (in your shell):</p> <pre><code>import sys\nprint(sys.version)\n</code></pre> <p>For me it printed: 3.8.0, which is good.</p> <p>You see above, that we had to import 'sys'. Otherwise sys wasn\u2019t available. Once we imported it, sys.version was the version of the current Python interpreter (the running environment above). The print statement just shows us what we\u2019ve imported. We did not need to import anything special to have \u2018print\u2019.</p> <p>Let\u2019s try just</p> <pre><code>sys.version\n</code></pre> <p>It also prints the value (3.8.0 for me). This is as we\u2019re in an interactive shell, but generally, unless we print something, an expression, as sys.version, or 3 + 4, is just yet another expression, and does not show in the output. We can omit the 'print' here, as in this exercise, we\u2019ll be in the interactive shell. Let\u2019s try:</p> <pre><code>3 + 4\n</code></pre> <p>We get a new value. To see the type of a value, we use for example:</p> <pre><code>type(3)\n</code></pre> <p>We get:</p> <p><code>&lt;class 'int'&gt;</code>  (an integer)</p> <p>What about \u2018hello\u2019, what is its type?</p> <p>We get:</p> <p><code>&lt;class 'str'&gt;</code> (a string)</p> <p>If you happen to use \u201chello\u201d it should be the same, both should work.</p>"},{"location":"part_I/#lists","title":"Lists","text":"<pre><code>my_list = [1, 2, 4]\ntype(my_list)\n</code></pre> <p>We should get:</p> <p><code>&lt;class 'list'&gt;</code></p> <p>Note above, that we assigned the value into a variable, my_list. This is handy as to use later in a program.</p> <p>A list can be also constructed as follows:</p> <pre><code>list('hello')\n</code></pre> <p><code>['h', 'e', 'l', 'l', 'o']</code></p> <p>The characters in the string became each an element in the list.</p> <p>With lists you can take slices, we\u2019ll use the variable my_list from above to demonstrate:</p> <pre><code>my_list[1:]\n</code></pre> <p><code>[2, 4]</code></p> <pre><code>my_list[:2]\n</code></pre> <p><code>[1, 2]</code></p> <p>Clarification: a single element, for example the first, will be my_list[0], a slice can be for example my_list[1:4], or as above (1:, means from the second to the end, and :2 means up to but not including index 2, therefore the first two elements).</p> <p>Note: the first index is 0. So the valid indices for a list \u2018lst\u2019 are: 0..len(lst) - 1 (ex. when len(lst) == 3 then the valid indices are 0, 1, 2).</p> <p>Slices are also lists, try to get the type of a slice. A slice is a \"copy\" of the original list. While there other ways to copy lists, the following is a common practice:</p> <pre><code>a = [1, 2, 3]\nb = a[:]\na[0] = 7\nprint(a, b)\n</code></pre> <p><code>[7, 2, 3] [1, 2, 3]</code></p> <p>The content of a list can be updated, for example like the following:</p> <pre><code>a = [1, 2, 3]\nprint(hex(id(a))) # printing the address of the object (in hex)\na[:2] = [4]\nprint(a)\nprint(hex(id(a)))\n</code></pre> <pre><code>0x7f05e06e28c0\n[4, 3]\n0x7f05e06e28c0\n</code></pre> <p>BTW, \u2018#\u2019 and then text is a comment, and can be used in a program to help the reader follow the logic. \u2018#\u2019 can start after some other code, and from there it is a comment.</p> <p>A list can be of mixed types, and also nested:</p> <pre><code>[1, 'Dog', my_list]\n</code></pre> <p><code>[1, 'Dog', [1, 2, 4]]</code></p> <p>But usually, we\u2019ll use lists where the elements are of the same type.</p>"},{"location":"part_I/#functions","title":"Functions","text":"<p>Let\u2019s have a function:</p> <pre><code>def add(a, b):\nreturn a + b\nadd(1, 4)\n</code></pre> <p><code>5</code></p> <pre><code>add('abc', 'def')\n</code></pre> <p><code>'abcdef'</code></p> <pre><code>add(1, 'def')\n</code></pre> <pre><code>Traceback (most recent call last):\n File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n File \"&lt;stdin&gt;\", line 2, in add\nTypeError: unsupported operand type(s) for +: 'int' and 'str'\n</code></pre> <p>So we\u2019ve seen that the same function, add, was good for integers and for strings. For strings \u2018+\u2019 means concatenation. When we tried mixed arguments. The call started as expected, but then \u2018+\u2019 is not defined between an integer and \u2018str\u2019. And so we got an error, or as it is called in Python an exception. If we wrote it in a software product, this would either be considered a bug, or it can be handled in run time, with some more control flow constructs (later).</p> <p>We can solve it by converting the integer first to a string:</p> <pre><code>str(1) + 'def'\n</code></pre> <p><code>'1def'</code></p> <p>There is an important aspect of Python, that we can already see above. Python does not enforce strong (static) typing. Python is a dynamic language, in the sense that one can pass as an argument a number, but also a string. The only important restriction is that the passed argument(s) adhere to the a protocol expected by the function (interface / contract). I refer you here to Wikipedia: Duck typing. In the example above, when we passed a number and a string, and the function add discovered it cannot use the '+' operator on them, an exception was raised. </p> <p>If we look for a second at the definition of the function above, we see that we\u2019ve started with the word \u2018def\u2019, then gave the name of the new function, then a parameters list in parentheses, then the column, and inside the function commands were indented with a tab or a few spaces. The last statement in a function is often return with the calculated value as the output of the function.</p> <pre><code>type(add)\n</code></pre> <p><code>&lt;class 'function'&gt;</code></p> <p>And we can also assign a function to a variable (note: not adding the parentheses   as in a call). The variable can later be activated (called).</p> <pre><code>a_func = add\na_func(9, 8)\n</code></pre> <p><code>17</code></p> <p>Remember, every time you have a value or a variable and you are not sure what it is, debug by printing its type.</p> <pre><code>print(type(print))\n</code></pre> <p><code>&lt;class 'builtin_function_or_method'&gt;</code></p> <pre><code>print(type(sys))\n</code></pre> <p><code>&lt;class 'module'&gt;</code></p> <pre><code>print(type(5 / 2))\n</code></pre> <p><code>&lt;class 'float'&gt;</code></p> <p>It is not anymore an integer. Dividing an integer by another integer results in a float.</p> <pre><code>5 // 2\n</code></pre> <p><code>2</code></p> <p>Here the result is an integer, and it wasn\u2019t rounded but rather truncated.</p>"},{"location":"part_I/#dicts","title":"Dicts","text":"<p>We\u2019ve seen before the type list, that is very useful. Another useful type is a dictionary, or dict. It is also referred to sometimes as associative memory. You have keys, and you have values. In a list, you use indices to address the content. Otherwise it is similar.</p> <pre><code>{'a': 4, 'b': 'Vier'} # One way to create a 'dict'\nmy_dict = dict() # yet another way to create a 'dict'\nmy_dict['my_key'] = 'your_value'\nmy_dict\n</code></pre> <p><code>{'my_key': 'your_value'}</code></p> <p>We have added an entry here to an existing dict. To add values to a list, we can for example do:</p> <pre><code>my_list.append('Marshmello')\nmy_list\n</code></pre> <p><code>[1, 2, 4, 'Marshmello']</code></p>"},{"location":"part_I/#tuples","title":"Tuples","text":"<p>There is also a useful type, a tuple. For example:</p> <pre><code>my_tuple = (1, 3, 'g')\nmy_tuple\n</code></pre> <p><code>(1, 3, 'g')</code></p> <pre><code>type(my_tuple)\n</code></pre> <p><code>&lt;class 'tuple'&gt;</code></p> <p>You can access elements of a tuple as you do with a list, yet a tuple is an immutable sequence.</p> <pre><code>my_tuple[0] = 2\n</code></pre> <pre><code>Traceback (most recent call last):\n File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nTypeError: 'tuple' object does not support item assignment\n</code></pre> <pre><code>my_tuple.append('Baby')\n</code></pre> <pre><code>Traceback (most recent call last):\n File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nAttributeError: 'tuple' object has no attribute 'append'\n</code></pre> <p>Tuples are useful in many cases. For example we can assign values to two variables at the same time.</p> <pre><code>old, new = 'Trump', 'Biden'\n</code></pre> <p>Here the parentheses are implicit. Note that the tuple from the right hand side is unpacked into the two variables on the left hand side (old and new).</p> <p>A function may need to return multiple values, and this can be done by returning a \u2018dict\u2019, or a \u2018list\u2019, but also a tuple makes the most sense.</p> <pre><code>for k, v in my_dict.items():\nprint(k, v)\n</code></pre> <p><code>my_key your_value</code></p> <p>Note, above is a for loop. Its structure somewhat resembles a function definition (the column, and the indentation). We got here two loop variables, k and v, as the function items of \u2018dict\u2019 instances returns an iterator of two values each iteration. We then printed those two in one \u2018print\u2019 statement. We happened to have only one key-value pair in the dict above.</p> <p>Here is another example of a 'for' loop:</p> <pre><code>my_sum = 0\nfor i in range(3):\nmy_sum += i\nmy_sum\n</code></pre> <p><code>3</code></p> <p>We initialized my_sum to zero, then we added 0, 1, and finally 2, to get 3.</p>"},{"location":"part_I/#ranges","title":"Ranges","text":"<pre><code>type(range(3))\n</code></pre> <p><code>&lt;class 'range'&gt;</code></p> <p>range resembes a list of consequtive integers that is not mutable. We did not need to create and initialize a list, and also the 'range' has the advantage that it keeps its values in its \"stomach\", and only makes them available when we iterate over it. If we want the explicit values, we can do:</p> <pre><code>list(range(5))\n</code></pre> <p><code>[0, 1, 2, 3, 4]</code></p> <p>We could have done above also simpler, by using the builtin function \u2018sum\u2019:</p> <pre><code>sum(range(3))\n</code></pre> <p><code>3</code></p> <p>Here is a small example of a function that returns two values, using the builtin functions \u2018min\u2019, and \u2018max\u2019.</p> <pre><code>def min_and_max(a_list):\nreturn min(a_list), max(a_list)\nmin_and_max(range(6))\n</code></pre> <p><code>(0, 5)</code></p> <pre><code>min_and_max([4, 1, 3])\n</code></pre> <p><code>(1, 4)</code></p> <p>Next we\u2019ll see boolean conditions and an if statement. This is also very important to control the flow of the program.</p> <pre><code>len(my_list)\n</code></pre> <p><code>4</code></p> <p>So the built-in function 'len' gives the length of a list. Good to know!</p> <pre><code>if len(my_list) &gt; 3:\nprint('it is')\n</code></pre> <p><code>it is</code></p> <p>And the type of the expression: len(my_list) &gt; 3, is:</p> <pre><code>type(len(my_list) &gt; 3)\n</code></pre> <p><code>&lt;class 'bool'&gt;</code></p> <p>Below is a function to reverse a string (or a list), and a call to that function.</p> <pre><code>def my_reverse(a_string):\nif len(a_string) &lt; 2:\nreturn a_string\nelse:\nreturn my_reverse(a_string[1:]) + a_string[0:1]\nmy_reverse('maar')\n</code></pre> <p>'raam'</p> <pre><code>my_reverse([3, 4, 5])\n</code></pre> <pre><code>[5, 4, 3]\n</code></pre> <p>Note, the implementation of the above function, is based on the function itself. This kind of implementation is called recursion. Recursion is a bit more advanced way of writing stuff, but sometimes it is actually simpler. If using recursion, pay attention to a stopping condition. The problems should become simpler and simpler, and in the final steps, you should return a simple value, as was the case above when the string was short and its reverse is actually the same value.</p> <p>I\u2019ve checked the builtin \u2018reversed\u2019 function. It behaves a little differently for a list, than for a string.</p> <pre><code>list(reversed([1,2,3]))\n</code></pre> <pre><code>[3, 2, 1]\n</code></pre> <pre><code># this is what we had before\nlist(reversed('gadol'))\n</code></pre> <pre><code>['l', 'o', 'd', 'a', 'g']\n</code></pre> <pre><code># but for a string, we\u2019ll get the list of characters (reversed).\n</code></pre> <p>Strings, have some functionality that we\u2019ve not explored before, for example:</p> <pre><code>\"hello\".upper()\n</code></pre> <pre><code>'HELLO'\n</code></pre>"},{"location":"part_I/#exercise","title":"Exercise","text":"<p>The exercise will be to approximate \ud835\udf45 by sampling. Let\u2019s say we have a circle with radius 1. What is its area? Now take a 1 by 1 square. And draw there a quarter of the above circle. The origin <code>(0, 0)</code> is the center of the (quarter) circle. The area of the square is <code>1 * 1 == 1</code>. The area of the quarter circle is <code>\ud835\udf45 / 4</code>. Let\u2019s sample a point from the rectangle. We\u2019ll do that by sampling x between 0 and 1, and y between 0 and 1. If <code>(x, y)</code> falls within the quarter circle, we\u2019ll count it in, otherwise, we\u2019ll not count it. After enough samples, the number of counted points, divided by the total number of samples, should approximate <code>\ud835\udf45 / 4</code>. As a check of your work, compare the value that you got for \ud835\udf45 (after multypling by 4) to the number you get from:</p> <pre><code>import math\nmath.pi\n</code></pre> <p>Guidance:</p> <p>The following code demonstrates sampling random numbers between 0 and 1 (each of type float). Remember that you need for each iteration two random numbers, one for x and another for y, and that the point <code>(x, y)</code> is at square distance of <code>x ** 2 + y ** 2</code> from the origin:</p> <pre><code>import random\nx, y = random.random(), random.random()\nsquare_distance = x ** 2 + y ** 2\n</code></pre> <p>Implement your code as a function that receives a parameter for the number of trials, and returns the approximated \ud835\udf45. It is a good idea to write the code in an editor of your preference, and to paste the code to the interactive Python shell, so you can avoid retyping the code for each fix.</p>"},{"location":"part_III/","title":"Part III","text":"<p>In this part of the course, we'll learn some more pure Python. We'll revisit some of the types and constructs we've seen before and learn some new tricks. We're also going to touch some bits and bobs that are nice to know and just waited till now.</p> <p>Let's look at the following code snippet.</p> <pre><code>def scan(a, b, c):\n\"Does something interesting with the arguments passed to it in the parameters 'a', 'b', and 'c'\"\nfor num in range(a, b):\nfor add in range(c):\nprint(num + add, end=', ')\nprint()\nscan(2, 5, 7)\n</code></pre> <pre><code>2, 3, 4, 5, 6, 7, 8, \n3, 4, 5, 6, 7, 8, 9, \n4, 5, 6, 7, 8, 9, 10, \n</code></pre> <p>The first observation I would like us to note is the string being the first expression of the function (\"Does something ..\"). This is a string like any other string, it is not a comment. And yet it is serving as a comment for the programmer, and for tools that help us edit, debug, and document the function. Those strings are called docstrings.  There is no issue in introducing those strings at the beginning of a function. You can introduce any expression anywhere you want in your program, this expression may be evaluated (depending on the program's control flow), and the program shall continue to the next expression (given that the expression does not raise an exception etc.). Having a string as the first expression had a special meaning and this convention is well integrated in the language and ecosystem.</p> <p>One can also access those strings programmaticaly:</p> <pre><code>scan.__doc__\n</code></pre> <p><code>\"Does something interesting with the arguments passed to it in the parameters 'a', 'b', and 'c'\"</code></p> <p>We note that 'range' can accept more than one argument. When two arguments are given, the first is the starting point, and the second is the value beyond the last value in the range. So 'range(3)' is equivalent to 'range(0, 3)'.</p> <p>We see a nested loop above. Note that importance of indentation. We must be exact with our indentation. When we return to a previous level, we should be in the exact column of the desired level. For example in line 7 the 'print' happens outside the add loop.</p> <p>BTW, a string (any strings) can be given in multiple lines, when it is wrapped with \"\"\" (or with '''). For docstring this is especially useful and often used.</p> <pre><code>def deep_neural_network(how_deep):\n\"\"\"\n  This function constructs a DNN based on your specification\n  Please take into consideration the benefits of a deep network,\n  versus the downsides.\n  \"\"\"\npass\n</code></pre> <p>Above, I defined a function, yet gave no implementation. I used pass to indicate I have no implementation (at least for now). We need to add 'pass' to make the indentation clear. If we omit it, and start new expressions at the same indentation of the function's definition, the interpreter would complain that we forgot indentation.</p> <p>We can still call our function, exactly as expected, with:</p> <pre><code>deep_neural_network(5)\n</code></pre> <p>The return value is <code>None</code> which is an important value to know, it just stands for \"nothing\". It is useful in many places, as a default value, or just when we don't have anything better to assign, or to pass as an argument.</p> <p>In 'JupyterLab', which is the interactive Python that I'm using, I can do now:</p> <pre><code>deep_neural_network?\n</code></pre> <p>Which gives me:</p> <pre><code>Signature: deep_neural_network(how_deep)\nDocstring:\nThis function constructs a DNN based on your specification\nPlease take into consideration the benefits of a deep network,\nversus the downsides.\nFile:      /tmp/ipykernel_566/1092418094.py\nType:      function\n</code></pre> <p>We've already seen 'list's, 'dict's, and 'tuple's. Let's add to this winning team also 'set's.</p>"},{"location":"part_III/#sets","title":"Sets","text":"<pre><code>s1 = set(\"hello\")\ns2 = set(\"bye\")\ns1, s2\n</code></pre> <p><code>({'e', 'h', 'l', 'o'}, {'b', 'e', 'y'})</code></p> <pre><code>s1 &amp; s2, s1 - s2, s2 - s1\n</code></pre> <p><code>({'e'}, {'h', 'l', 'o'}, {'b', 'y'})</code></p> <p>Note that sets use the same curly brackets as dicts, '{}'. You can initialize a set with curly brackets, as in:</p> <pre><code>nodes_visited_by_now = {'A', 'B', 'C'}\n</code></pre> <p>If you wish to assign an empty set to a variable, use 'set()', as an empty brackets '{}' will be interpreted with an empty dict.</p> <p>A lot of times, just by using those built-in containers you can achieve very complicated functionality. We will also learn in next parts to create our own classes (object oriented), yet most of your code can often be realized with the basic constructs, types, and containers, available for free in the language, familiar to your fellow programmers, and already tested and optimized for you. Try to avoid cluttering your program with too many new constructs and ideas. This is a least my recommendation, which I picked at the times I was using Ruby and following the Ruby's community. I think it is also very relevant to Python.</p>"},{"location":"part_III/#comprehensions","title":"Comprehensions","text":"<p>There are a lot more goodies to learn about Python, we've only scratched the surface. Let's learn about comprehension.</p> <p>Consider this list of strings:</p> <pre><code>words = \"Welcome to my show!\".split(); words\n</code></pre> <p><code>['Welcome', 'to', 'my', 'show!']</code></p> <p>When we 'split' a string we get a list of strings, where the splitting character(s) are removed.</p> <p>Let's say we want to lower all words (we see that there is only one word, 'Welcome', at the moment but for arbitrary input we don't know in advance). The following code shall do the work:</p> <pre><code>words_lower = []\nfor word in words:\nwords_lower.append(word.lower())\nwords_lower\n</code></pre> <p><code>['welcome', 'to', 'my', 'show!']</code></p> <p>There is a very useful construct that is arguably more readable and may be even faster.</p> <pre><code>words_lower = [word.lower() for word in words]\n</code></pre> <p>words_lower is now a list with values as before, in our example, <code>['welcome', 'to', 'my', 'show!']</code>. Since the loop only serves for going over all the items in the list words we might as well have it inside the creation of the new list words_lower.  This construct is called list comprehension. With list comprehension we can also filter out values. For example, let's filter out words that are in the set <code>{'from', 'to', 'cc'}</code>.</p> <pre><code>words_filtered = [word for word in words_lower if word not in {'from', 'to', 'cc'}]; words_filtered\n</code></pre> <p><code>['welcome', 'my', 'show!']</code></p> <p>Note the condition at the end of the list comprehension, which allows only words that are not in the given set of words. We could have combine lower-casing the words and the filtering. Make your own judgement what is more readable given your situation.</p> <p>Let's find out how many characters in the following strings.</p> <pre><code>fruits = [\"apple\", \"banana\", \"orange\"]\nlens = {fruit: len(fruit) for fruit in fruits}; lens\n</code></pre> <p><code>{'apple': 5, 'banana': 6, 'orange': 6}</code></p> <p>Which shows us that we can use comprehensions also with 'dict's. We've built a new dict on-the-fly while iterating over the entries in fruits.</p> <p>In the next example, we'll calculate a \"reverse index\" to a given dict.</p> <pre><code>roman_numbers = {'I': 1, 'V' : 5, 'X': 10}\narabic_numbers = {v: k for k, v in roman_numbers.items()}; arabic_numbers\n</code></pre> <p><code>{1: 'I', 5: 'V', 10: 'X'}</code></p> <p>If we wrap an iterable, such as a list, or a string, with 'enumerate', we get a new iterable that gives us tuples. The first component of a tuple is the index of the matching item, and the second component is the original item in the original iterable. A picture (code snippet) is worth a thousand words:</p> <pre><code>enumerate(list(\"groceries\")), enumerate(\"groceries\") \n</code></pre> <p><code>(&lt;enumerate at 0x7f1c281c2f00&gt;, &lt;enumerate at 0x7f1c281c29c0&gt;)</code></p> <p>We turn a string into a list of characters and wrap the list with an 'enumerate'. The output tells us that now we have an 'enumerate'. We also demonstrate that with going directly from the string, being an iterable and wrapping it directly with 'enumerate'. We've ended with two different 'enumerate' objects. To show the values, we can construct a list out of the 'enumerate' object we have. We could have iterated over the 'enumerate' or use it in a comprehension expression. The list construction will serve us here.</p> <pre><code>list(enumerate(\"groceries\"))\n</code></pre> <pre><code>[(0, 'g'),\n (1, 'r'),\n (2, 'o'),\n (3, 'c'),\n (4, 'e'),\n (5, 'r'),\n (6, 'i'),\n (7, 'e'),\n (8, 's')]\n</code></pre> <p>And we see our expected tuples.</p> <p>Time for a small example. Let's build a function that takes a roman number as a string and returns the equivalent number.</p> <pre><code>def from_roman(roman):\n\"\"\"\n    This function receives a roman number as a string and returns the number.\n    &gt;&gt;&gt; from_roman(\"VII\")\n    7\n    &gt;&gt;&gt; from_roman(\"IV\")\n    4\n    &gt;&gt;&gt; from_roman(\"XIV\")\n    14\n    &gt;&gt;&gt; from_roman(\"XVIII\")\n    18\n    &gt;&gt;&gt; from_roman(\"MMM\")\n    ValueError                                Traceback (most recent call last)\n        ...\n    ValueError: Don't know to handle 'M'.    \n    \"\"\"\nmapping = {'I': 1, 'V': 5, 'X': 10}\narabic = 0\nprev_val = 0\nfor c in reversed(roman):\nval = mapping.get(c, None)\nif val is None:\nraise ValueError(f\"Don't know to handle '{c}'.\")\nif val &gt;= prev_val:\narabic += val\nelse:\narabic -= val\nprev_val = val\nreturn arabic\n</code></pre> <p>My logic above was to go from right to left, to add when we see the same value or a bigger value (ex. from I to V), and to subtract when we see a smaller value (ex. from V to I).</p> <p>To go from right to left, I've wrapped the input string roman with 'reversed'. 'reversed' is an iterable that gives us the items in a reversed order. When accessing my mapping dict, I have used 'get' rather than indexing notation as to avoid an exception when a key is not present. But then I have \"manually\" raises an exception of type 'ValueError' when we got a character that is not currently supported. Note the f-string used when creating the exception. f-strings are a template, and we fill the values in, between currly brackts, with Python expression. This is very convenient way to format a string.</p> <p>The '+=' and '-=' operators are used here and mean the same as is the case in the C language. Try to avoid using those special operators when working with complex objects, yet for simple variables of type integer in this example, this should work perfectly.</p> <p>The reason it may be risky to use '+=' and '-=' with objects is that a lot of times there is not explicit implementation of the operator. Then the operator '+=', as an example, is implicitly converted for example to <code>a = a + 1</code> which while seems benign actually results in a new object begin assigned to a in the example. If some other variable or data structure (for example a dict) used to reference a one may believe they have the handle to the up-to-date a yet it is not the case. They are probably still referencing the old a. Just keep that in mind.</p>"},{"location":"part_III/#doctest","title":"Doctest","text":"<p>Last thing to notice is that I've added examples in the docstring. This are of the form <code>&gt;&gt;&gt; expression (newline) expected output</code>. This adds clarity for the intended use, it becomes part of the documentation. But there is more! One can actually execute those tests with Python built-in doctest.</p> <p>In a lot of Python file, you'll find a 'main' function, and toward the bottom of the file, an 'if' statement:</p> <pre><code>def main():\n...\nif __name__ == \"__main__\":\nmain()\n</code></pre> <p>When you run the file with <code>python my_file.py</code> the expression in the bottom is evaluated to True and the code in the main function is executed. When the 'if' statement is missing, code in functions is not called, so you may end up not really running anything. Only code outside functions is executed. It is a good practice to wrap your code in functions and call the starting point, say, main, from such an 'if' statement. A file with only functions can still be useful as a part of a module (and be called from outside the file, or from the command line with the -m flag).</p> <p>Whole this long detour was to show the following:</p> <pre><code>... # code containing potentially doctests\nif __name__ == \"__main__\":\nimport doctest\ndoctest.testmod()\n</code></pre> <p>The snippet above should look for doctests in the file and should execute them, verifying the output.</p> <p>There is yet another very useful function when we're dealing with sequences (a list for example) and iterations. 'zip' allows us to traverse multiple lists, as an example, together. Examining the first elements, and then the second elements, etc.</p> <pre><code>list(zip(range(3), \"abc\"))\n</code></pre> <p><code>[(0, 'a'), (1, 'b'), (2, 'c')]</code></p> <p>'zip' is useful in many cases, and you can also use more than two lists (or other iterables).</p>"},{"location":"part_III/#exrecises","title":"Exrecise(s)","text":""},{"location":"part_III/#read-alternative-implementation","title":"Read alternative implementation","text":"<p>I've implemented above from_roman with the latest things we've learn. Not sure this implementation is better. Up to you to decide. Take from it what you like. Nothing wrong with old good loops. One will often mix and match.</p> <p>Make sure you can follow what we've done here. Can you see why using 'reversed' was not required with this implementation?</p> <pre><code>def from_roman2(roman):\n\"\"\"\n    This function receives a roman number as a string and returns the number.\n    &gt;&gt;&gt; from_roman2(\"VII\")\n    7\n    &gt;&gt;&gt; from_roman2(\"IV\")\n    4\n    &gt;&gt;&gt; from_roman2(\"XIV\")\n    14\n    &gt;&gt;&gt; from_roman2(\"XVIII\")\n    18\n    &gt;&gt;&gt; from_roman2(\"MMM\")\n    ValueError                                Traceback (most recent call last)\n        ...\n    ValueError: Don't know to handle 'M'.    \n    \"\"\"\nif len(roman) &lt; 1:\nreturn 0\nmapping = {'I': 1, 'V': 5, 'X': 10}\nvalues = [mapping.get(c, None) for c in roman]\nif None in values:\nc = next(c for c, v in zip(roman, values) if v is None) # returns the (next) first occurrence\nraise ValueError(f\"Don't know to handle '{c}'.\")\n# the sign +1 or -1\nadd_or_sub = [1 if v1 &gt;= v2 else -1 for v1, v2 in zip(values[:-1], values[1:])]\nassert len(values) - 1 == len(add_or_sub) # make sure we do what we think we do\nadd_or_sub.append(+1) # right most element is added.\nreturn sum(v * s for v, s in zip(values, add_or_sub))\n</code></pre>"},{"location":"part_III/#removing-duplicates-from-a-list","title":"Removing duplicates from a list","text":"<p>You are given a list. The list contains potential duplicates. Your task is to have the list without the duplicates.</p> <p>List comprehension? Using a set? Should you create a new list or modify the existing list? In your implementation, do you guarantee to preserve the order of the (unique) elements?</p> <p>Let's show-and-tell. Let's compare our various possible solutions and approaches.</p>"},{"location":"part_II_np/","title":"Part II (numpy)","text":"<p>We take a little break from pure Python, and introduce a very useful package numpy. It is not part of the standard library yet easily installed, for example with (below is done in an OS shell, it is not Python):</p> <pre><code>pip install numpy\n</code></pre> <p>If you're working with 'pip' or with 'conda' please go and install 'numpy'. For me, 'numpy' was already available with https://www.python.org/shell/. I've verified it with:</p> <pre><code>import numpy as np\nnp.__version__\n</code></pre> <p><code>'1.21.6'</code></p> <p>(Packages also have their version, which is also very important concept to wrap your head around. For now we are good.)</p> <p>We import the package and follow the convention to alias it np:</p> <pre><code>import numpy as np\ntype(np)\n</code></pre> <p><code>module</code></p> <p>Why did I say a package? A package may contain, or bring with its installation, multiple Python modules. We\u2019ll talk about it later (what is a Python module?, how we create a package?, and relevant considerations).</p> <p>So why is it worth it to learn about 'numpy'? Well, first it is an example of yet another useful package. Python is great, yet it is really great thanks to the ecosystem around it. There are packages for data science, packages that are part of web frameworks, packages for developing games. In particular, 'numpy', appears almost always (at least with Python software I've played with).</p> <p>The theme of 'numpy' is linear algebra. For example, one can wrap a list into 'numpy.ndarray' (n-dimensional array).</p> <pre><code>arr = np.array([1, 2, 3])\narr.shape\n</code></pre> <p><code>(3,)</code></p> <p>len(arr) will also work and shall return 3.</p> <p>There exists a standard module array in Python that also deals with memory efficient arrays. We'll skip 'array' and jump directly to 'numpy' which is what people often do these days. Potentially 'numpy' is making use of 'array' behind the scenes.</p> <p>The 'shape' returns a tuple where each entry is the length of the relevant dimension. Note the comma in (3,). This is to distinguish this value, which is a tuple, from (3) which is just the scalar 3 after the expression is evaluated.</p> <p>With 'numpy' one can \"index\" an array with a list of integer indices:</p> <pre><code>arr = np.array([1, 2, 3, 4, 5])\narr[[0, 2]]\n</code></pre> <p><code>array([1, 3])</code></p> <p>Which allows us also to take elements multiple times as needed:</p> <pre><code>arr[[0, 2, 2, 2, 2]]\n</code></pre> <p><code>array([1, 3, 3, 3, 3])</code></p> <p>One can also access a 'numpy' array with a boolean list where each entry corresponds to the matching place in the 'numpy' array. The boolean list needs to be of the matching length.</p> <pre><code>arr[[True, True, False, False, True]]\n</code></pre> <p><code>array([1, 2, 5])</code></p> <p>This is useful when we have (computed in previous code) indicators. For example:</p> <pre><code>ind = arr % 3 == 0\nlen(ind), arr[ind]\n</code></pre> <p><code>(5, array([3]))</code></p> <p>Note that with the integer indices, we've ended with a 'numpy' array of the same length as the indices. With the boolean indicators list, the result is a 'numpy' array of the length of the total number of Trues in the indicators list.</p> <p>An important observation is that while a simple list can contain heterogeneous values, a 'numpy' array is expected to hold values of the same type in all cells. In addition to many goodies that we'll see soon, 'numpy' is intended to make the calculations fast and vectorized. Vectorisation is a technique where special hardware manipulate multiple cells at the same time.</p> <p>To find the type of the elements themselves, use:</p> <p><pre><code>arr.dtype\n</code></pre> In this example it is <code>dtype('int64')</code>.</p> <p>To find the dimension of a 'numpy' array, one can do:</p> <pre><code>len(arr.shape)\n</code></pre> <p><code>1</code></p> <p>Here BTW we see that 'len' works also on a tuple.</p> <p>I've recently learned that one can also just issue:</p> <pre><code>arr.ndim\n</code></pre> <p>Which should give the same result <code>1</code>.</p> <p>To find how many elements in a 'numpy' array, I would go for:</p> <pre><code>np.prod(arr.shape)\n</code></pre> <p><code>3</code></p> <p>Above, we see a nice utility function from 'numpy' that takes an iterable, in this case the tuple arr.shape, and returns the product of the elements.</p> <p>Let's go to the next dimension:</p> <pre><code>mat = np.array([[1, 2], [1, 0], [2, 1]]); mat\n</code></pre> <pre><code>array([[1, 2],\n       [1, 0],\n       [2, 1]])\n</code></pre> <p>We used ';' to separate two expressions. The last expression mat is what we see in the interactive shell. We see that we got a matrix with 3 rows and 2 columns.</p> <pre><code>len(mat.shape), np.prod(mat.shape)\n</code></pre> <p><code>(2, 6)</code></p> <p>Here we used ',' between the two expressions. This gave us the tuple (2, 6). The first element of the tuple is the dimension of mat and the other is the count of elements in mat (similar to what we've verified above for arr).</p> <p>A 2-dimentional 'numpy' array or, a \"matrix\" has two axes; 0 and 1. One axis is the rows and the other is the columns. Let's see that in action:</p> <pre><code>np.sum(mat), np.sum(mat, axis=0), np.sum(mat, axis=1)\n</code></pre> <p><code>(7, array([4, 3]), array([3, 1, 3]))</code></p> <p>We can see that without the axis parameter we get a scalar which is the sum of all the elements. With axis=0 the rows collapse and we get the summation per columns. With axis=1 the columns collapse, and we end up with as many entries in the result 'numpy' array as we had rows. </p>"},{"location":"part_II_np/#vectorization","title":"Vectorization","text":"<p>'numpy' speeds calculations. In addition to the code being optimized, written probably in C, etc. There is an important concept of vectorization. For example, add two 'numpy' arrays of the same length, element-wise. There are at least two advantages, 1. The code does not contain an explicit loop, and 2. The implementation may make use of hardware that can indeed calculate multiple entries in parallel.</p> <pre><code>a = np.random.randn(5_000_000)\nb = np.random.randn(5_000_000)\n</code></pre> <p>The vectorization way (use 'numpy' addition between two 'numpy' arrays).</p> <pre><code>%%time\nc1 = a + b\n</code></pre> <pre><code>CPU times: user 815 \u00b5s, sys: 10.3 ms, total: 11.1 ms\nWall time: 9.58 ms\n</code></pre> <p><code>%%time</code> is a magic command in a Jupyter notebook cell. With a \"na\u00efve\" loop.</p> <pre><code>%%time\nc2 = []\nfor i in range(len(a)):\nc2.append(a[i] + b[i])\nc2 = np.array(c2)\n</code></pre> <pre><code>CPU times: user 1.18 s, sys: 57 ms, total: 1.23 s\nWall time: 1.23 s\n</code></pre> <p>We'll learn later to write \"simple computation loops\" as follows, we're still not as fast as the 'numpy' vectorization.</p> <pre><code>%%time\nc3 = np.array([ia + ib for ia, ib in zip(a, b)])\n</code></pre> <pre><code>CPU times: user 594 ms, sys: 72.7 ms, total: 667 ms\nWall time: 667 ms\n</code></pre> <p>Just to make sure we got the same results we'll used the following. Again potential for vectorization by 'numpy'.</p> <pre><code>np.array_equal(c1, c2) and np.array_equal(c2, c3) \n</code></pre> <p><code>True</code></p> <p>Prefer 'np.array_equal' over '==', among other reasons, as the arrays may be of different lengths, in which case you probably would like to get a simple 'False' rather then an exception (a run-time error). There is also a useful 'numpy' function to compare for \"about equal\". 'np.allclose'.</p>"},{"location":"part_II_np/#reshaping","title":"Reshaping","text":"<p>A 'numpy' array can be \"reshaped\".</p> <pre><code>aa = a.reshape((1000, -1)); a.shape, aa.shape\n</code></pre> <p><code>((5000000,), (1000, 5000))</code></p> <pre><code>a[0], a[1], aa[0, 0], aa[0, 1]\n</code></pre> <pre><code>(-1.752274499506939,\n -0.3307574792704177,\n -1.752274499506939,\n -0.3307574792704177)\n</code></pre> <pre><code>aa[0, 0] = np.pi\na[0], aa[0, 0]\n</code></pre> <p><code>(3.141592653589793, 3.141592653589793)</code></p> <p>When is this (reshaping) needed? Think for example about an image in HWC (High-Width-Channel) format and then you realize the utility function actually needs the format to be CHW. It is easy with 'numpy'. You can also turn a HW (monochrome) into a HMC (add a dimension) when needed.</p> <pre><code>aa.reshape((1000, 5000, -1)).shape\n</code></pre> <p><code>(1000, 5000, 1)</code></p> <p>With slicing notation.</p> <pre><code>aa[:, :, np.newaxis].shape\n</code></pre> <p><code>(1000, 5000, 1)</code></p> <p>'np.newaxis' is just an alias to 'None'.</p> <pre><code>aa[:, :, None].shape\n</code></pre> <p><code>(1000, 5000, 1)</code></p> <pre><code>aa[np.newaxis, :, :].shape\n</code></pre> <p><code>(1, 1000, 5000)</code></p> <pre><code>aa[np.newaxis, :, :].transpose(0, 2, 1).shape\n</code></pre> <p><code>(1, 5000, 1000)</code></p>"},{"location":"part_II_np/#some-more-examples","title":"Some more examples","text":"<pre><code>x = np.linspace(0, 2 * np.pi, 52)\nx[:5]\n</code></pre> <pre><code>array([0.        , 0.12319971, 0.24639942, 0.36959914, 0.49279885])\n</code></pre> <pre><code>import matplotlib.pyplot as plt\nplt.plot(x, np.sin(x))\nplt.scatter(x, np.sin(x))\nplt.xlabel(\"x\")\nplt.ylabel(\"sin(x)\")\nplt.title(\"The \" + r\"$\\bf{x}$\" + \" values were taken with \" +r\"$\\bf{np.linspace}$\");\n</code></pre> <p>You can also experiment with 'np.arange' which accepts the step's size rather than the desired number of values.</p> <p>Here is an example of a usage of the 'np.where' function.</p> <pre><code>a_or_3 = np.where(a &gt; b, a, 3)\na_or_3.shape, a_or_3[:5]\n</code></pre> <pre><code>((5000000,),\n array([ 3.14159265,  3.        ,  0.49121537, -0.38382345,  0.31436233]))\n</code></pre> <p>Note that a &gt; b is a boolean array of size 5_000_000 in this example. a is an array of size 5_000_000. The third argument could have been also an array, but we've just passing 3 which is okay, as a single element is broadcastable to the shape of the other two arguments (the third argument is treated as an array full with this single value).</p> <p>As an answer to \"I have two numpy arrays with floating point values and I am trying to find the indices where the numbers are approximately equal (floating point comparisons).\", the following was suggested (when only one argument to 'np.where' the indices are returned):</p> <pre><code>np.where(np.isclose(x, y))\n</code></pre> <p>Let's try the following advanced exercise. We're given a matrix. We return another matrix according to the following rules. If a cell in the input matrix is zero, the matching \"cell\" in the return matrix will be 3 by 3 zeros. Otherwise, a none zero value, will result with a matching \"cell\" of 3 by 3 ones. It will get soon clear when you'll see the example output.</p> <pre><code>def inflate(input_matrix):\nres = []\nfor row in range(0, input_matrix.shape[0]):\nres_row = []\nfor col in range(0, input_matrix.shape[1]):\nsubmatrix = input_matrix[row:row + 1, col:col + 1]\ntransformed = np.zeros((3, 3)) if submatrix == 0 else np.ones((3, 3))\nres_row.append(transformed)\nres.append(np.concatenate(res_row, axis=1))\nreturn np.concatenate(res, axis=0)\nprint(mat, end=\"\\n\\n\")\ninflate(mat)\n</code></pre> <pre><code>[[1 2]\n [1 0]\n [2 1]]\n\narray([[1., 1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1., 1.],\n       [1., 1., 1., 0., 0., 0.],\n       [1., 1., 1., 0., 0., 0.],\n       [1., 1., 1., 0., 0., 0.],\n       [1., 1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1., 1.]])\n</code></pre> <p>Note that, on line 6 we access a submatrix (in this case just 1 by 1) using indices (similar to slicing in lists).</p> <p>The assignment to the variable transformed on line 7 needs a clarification. This is the equivalent of the ternary operator from 'C/C++'. In 'C' we have <code>cond ? val_when_true : val_when_false</code>. With Python this would be <code>val_when_true if cond else val_when_false</code>.</p> <p>Maybe there is a smarter way to achieve what was done above in the function inflate. That is what I came up with. I've came with above code while playing with Abstraction and Reasoning Corpus (ARC), see Oren's ARC DSL.</p> <p>And now it is your turn.</p>"},{"location":"part_II_np/#exercise","title":"Exercise","text":"<p>This course is originated in the Netherlands . Which means that we need to do something with a windmill. Here are some building blocks that may help.</p> <pre><code>np.tri(4)\n</code></pre> <pre><code>array([[1., 0., 0., 0.],\n       [1., 1., 0., 0.],\n       [1., 1., 1., 0.],\n       [1., 1., 1., 1.]])\n</code></pre> <pre><code>np.tri(4).T # transpose\n</code></pre> <pre><code>array([[1., 1., 1., 1.],\n       [0., 1., 1., 1.],\n       [0., 0., 1., 1.],\n       [0., 0., 0., 1.]])\n</code></pre> <pre><code>np.flip(np.tri(4), axis=0)\n</code></pre> <pre><code>array([[1., 1., 1., 1.],\n       [1., 1., 1., 0.],\n       [1., 1., 0., 0.],\n       [1., 0., 0., 0.]])\n</code></pre>"},{"location":"part_IV/","title":"Part IV","text":"<p>In this part we'll dive a bit into functional programming. There is a very good support for functional programming in Python. A lot of Python code mixes functional programming with object oriented programming, whatever makes sense given the context.</p> <p>We've already seen the ability to declare functions, and to assign a function to a variable. A function can also be passed as an argument.</p> <pre><code>arr = [(1, 'a'), (7, 'b'), (3, 'c'), (4, 'd'), (2, 'e')]\nsorted(arr)\n</code></pre> <p><code>[(1, 'a'), (2, 'e'), (3, 'c'), (4, 'd'), (7, 'b')]</code></p> <p>What do we see? We had a list with tuples arr. We used the built-in function 'sorted' that receives an 'iterable' and returns a list with the element sorted. We note that when comparing tuples, the first element takes precedance over the other elements. And so the tuples were ordered by the number.</p> <p>Please note that arr is still with the original order.</p> <pre><code>arr\n</code></pre> <p><code>[(1, 'a'), (7, 'b'), (3, 'c'), (4, 'd'), (2, 'e')]</code></p> <p>What we got is a new list (a new object). 'list's also have the functionality to sort in-place.</p> <pre><code>arr.sort(); arr\n</code></pre> <p><code>[(1, 'a'), (2, 'e'), (3, 'c'), (4, 'd'), (7, 'b')]</code></p> <p>Calling 'sort' on a list is the \"object-oriented\" way. The list arr was changed. This may be desirable or not. With functional programming we'll prefer immotable objects. That way we can worry less about multi-threading (and there are other benefits).</p> <p>In this part, we'll show more examples from the functional programming way.</p> <p>What if we wanted to sort by the string (a single character here)? Luckily 'sorted' has an optional parameter 'key'. It is optional as there is a default of None, and when 'key' is not provided, the default None is intepreted as just compare the elements themselves. Let's use the 'key' parameter.</p> <pre><code>def by_the_character(t):\nreturn t[1]\nsorted(arr, key=by_the_character)\n</code></pre> <p><code>[(1, 'a'), (7, 'b'), (3, 'c'), (4, 'd'), (2, 'e')]</code></p>"},{"location":"part_IV/#lambda-functions","title":"Lambda functions","text":"<p>We can see that now we have a list sorted by the second elements of the tuples. We can also define functions \"on-the-fly\", without a spacific name. Those are lambda functions. Lambda functions do not require a return statement, it is implicit from the last expression in the \"function\".</p> <pre><code>sorted(arr, key=lambda t: t[1])\n</code></pre> <p><code>[(1, 'a'), (7, 'b'), (3, 'c'), (4, 'd'), (2, 'e')]</code></p> <p>Both options are as valid, using an explicit function, or using a lambda function. Pick the one most appropriate in the relevant context.</p>"},{"location":"part_IV/#map-filter","title":"Map, Filter","text":"<p>There is yet another way to map one iterator into another, and to filter elements. We've seen explicit for loops, and we've seen comprehensions. There are also built in 'map' and 'filter' functionalities.</p> <pre><code>sentence = \"The cat sat on the mat.\"\nmap(str.upper, sentence.split())\n</code></pre> <p><code>&lt;map at 0x7fbb082cdb20&gt;</code></p> <p>We got a map object. To see the values, we can construct a list out of the map (which is an iterable):</p> <pre><code>list(map(str.upper, sentence.split()))\n</code></pre> <p><code>['THE', 'CAT', 'SAT', 'ON', 'THE', 'MAT.']</code></p> <p>The function we used in the first argument str.upper was taken from the type 'str'. Another similar code can be done with using a dict for translations.</p> <pre><code>en_to_nl = {\n'The': 'De',\n'cat': 'kat',\n'sat': 'zat',\n'on': 'op',\n'the': 'de',\n'mat.': 'mat.',\n}\nlist(map(en_to_nl.get, sentence.split()))\n</code></pre> <p><code>['De', 'kat', 'zat', 'op', 'de', 'mat.']</code></p> <p>This time the function 'get' was taken from a specific object en_to_nl (a dict in this case). As long as a simple call, with one argument, which is the current element, is possible it should work.</p> <p>Note that we gave the dict on multiple lines. Python interpreter is happy with this syntax given that we've openned with curly brackets '{'. A long expression can be placed in parantheses. This should make the program a bit more readable.</p> <pre><code># just a random example..\npartial_result = (\nf1(3) +\nf2(4) / f3(5) -\n(2 if x &gt; y else 4)\n)\n</code></pre> <p>What if we needed a default, say when we don't have a translation for a word, to add the original word in uppercase?</p> <pre><code>list(map(\nlambda en_word: en_to_nl.get(en_word, en_word.upper()),\n\"The dog sat on the mat.\".split()\n))\n</code></pre> <p><code>['De', 'DOG', 'zat', 'op', 'de', 'mat.']</code></p> <p>When to use 'map' or 'filter' and when to use comprehensions? The expression above could have been written as follows:</p> <pre><code>[\nen_to_nl.get(en_word, en_word.upper())\nfor en_word in \"The dog sat on the mat.\".split()\n]\n</code></pre> <p><code>['De', 'DOG', 'zat', 'op', 'de', 'mat.']</code></p> <p>Note that we did not have to use 'list', as we're already building one, and also the expression was given in a straight forward manner rather than through a (lambda) function.</p> <p>The reason that we needed 'list' when we worked with 'map' is that the caculation and memory required did not happen yet when we called 'map'. 'map' is \"lazy\" in the sense that no list was constructed yet, and no element was \"mapped\" yet. Only during the iteration the transformation happens, one element at a time, and those are collected into a list, only when we explicitly construct a list from the iterator items (by wrapping the map in 'list'). There are situations, in which a pipeline can be constructed, by passing 'map' objects into other 'map' or 'filter' objects, and only at the last step we iterate over the results, or construct a list out of those. This can save time and memory. It might result also with a bit clearer code.</p>"},{"location":"part_IV/#generator","title":"Generator","text":"<p>To be fair with comprehensions, there is a similar way to do \"lazy\" evaluation. One can also do above with \"comprehensions\" that use '()' instead of '[]'.</p> <pre><code>l = [1, 2, 3]\nl_squared = (x ** 2 for x in l)\ntype(l_squared)\n</code></pre> <p><code>generator</code></p> <pre><code>[x for x in l_squared if x &gt; 2]\n</code></pre> <p><code>[4, 9]</code></p> <p>Pay attention to the fact that the generator is now exhausted:</p> <pre><code>[x for x in l_squared if x &gt; 2]\n</code></pre> <p><code>[]</code></p> <p>Meaning that if we wanted to iterate over the elements again, we needed to \"restart\" the generator, for example by issuing again <code>l_squared = (x ** 2 for x in l)</code>.</p> <p>Using '()' instead of '[]' is actually called generator expression rather than comprehension. There are places when you can even introduce such a generator expression without the parenthesis. For example:</p> <pre><code>list(x ** 2 for x in range(3))\n</code></pre> <p><code>[0, 1, 4]</code></p> <p>Just to wrap the discussion on 'map' and 'filter' vs. comprehensions, let's have above also with 'map' and 'filter'.</p> <pre><code>l = [1, 2, 3]\nl_squared = map(lambda x: x ** 2, l)\nlist(filter(lambda x: x &gt; 2, l_squared))\n</code></pre> <p><code>[4, 9]</code></p> <p>Find your own zen with either way. You can mix and match as suits you.</p> <p>A generator is a conviniet was to create an iterable. A function that contains one or more yield expression is a generator.</p> <pre><code>def my_gen(l):\nfor e in l:\nyield e + 1\ng = my_gen([1, 2, 3]); g\n</code></pre> <p><code>&lt;generator object my_gen at 0x7fbaf1426cf0&gt;</code></p> <p>If we wish to see the items, we need to iterate over the generator.</p> <pre><code>list(g)\n</code></pre> <pre><code>[2, 3, 4]\n</code></pre> <p>As the generator is now exhausted, if we try above again we'll end up with <code>[]</code>. But luckily we have a function that we can call again to receive a fresh copy of a generator.</p> <pre><code>list(my_gen([1, 2, 3]))\n</code></pre> <p><code>[2, 3, 4]</code></p> <p>A generator is usuful in many situations. Let's have a random numbers generator. Note that if is to wrap a list around it we're probably going to fail as the iterator we're just defining is infinite (try at your own risk). Therefore we'll use it in another way.</p> <pre><code>import random\ndef random_generator():\nwhile True:\nyield random.random()\nfor i, r in zip(range(4), random_generator()):\nprint(i, r)\n</code></pre> <pre><code>0 0.04245109121862101\n1 0.4875224375865369\n2 0.5398443861135133\n3 0.16015149066151046\n</code></pre> <p>It seems that 'zip' stops as soon as one of its iterators is exhausted. In this case it was the 'range'.</p> <pre><code>for i1, i2 in zip(range(4), range(3)):\nprint(i1, i2)\n</code></pre> <pre><code>0 0\n1 1\n2 2\n</code></pre> <p>Note that the infinite 'while' loop above should not cause our program to never end, as after each 'yield' the control is returned to the place in code iterating over the generator.</p> <p>There are other ways to create iterators (ex. for your custom objects / classes, or a wrapper for third party constructs), and there are other usages to generators (ex. co-routines). Let's keep that in mind, yet for now, let us get acquainted with generators and make the best usage of them when relevant.</p> <p>A few more words on 'iterator's, 'generator's, and on 'map'. An alternative to a 'for' loop can be to call 'next' on the iterator. For example, to find the occurance in a list, one can use:</p> <pre><code>l = list(range(2, 20))\nitem = next(x for x in l if x % 7 == 0); item \n</code></pre> <p><code>7</code></p> <p>Using 'next' can be useful also with a 'map' or a 'generator'. When the iterator is exhausted. A StopIteration is thrown. We useally don't need to worry about it, as in a 'for' loop this is handled for us. In the example of finding the first (or the next) occurance, we can use an extra argument to 'next' which will act as the default then the iterator is exhausted instead of throwing the exception.</p> <pre><code>next((x for x in range(3) if x &gt; 7), \"No such item\")\n</code></pre> <p><code>'No such item'</code></p> <pre><code>next((x for x in range(30) if x &gt; 7), \"No such item\")\n</code></pre> <p><code>8</code></p> <pre><code>my_g = (x for x in range(2))\nprint(next(my_g))\nprint(next(my_g))\nprint(next(my_g))\n</code></pre> <pre><code>0\n1\n---------------------------------------------------------------------------\nStopIteration                             Traceback (most recent call last)\nCell In[10], line 4\n      2 print(next(my_g))\n      3 print(next(my_g))\n----&gt; 4 print(next(my_g))\n\nStopIteration:\n</code></pre> <p>'map' can take multiple iterators, which can be useful similar to 'zip'.</p> <pre><code>import operator\nlist(map(operator.add, range(3), range(4)))\n</code></pre> <p><code>[0, 2, 4]</code> </p>"},{"location":"part_IV/#exrecise","title":"Exrecise","text":"<p>We are given a text. The text contains paragraphs, each paragraph contains sentences, and each sentence contains words. A paragraph is separated from the previous one, by an empty line. A sentence ends with one of {'.', '?', '!'}. Words are separated with ' '. We want to report for every word in the text all the places that it appeared. A place is indicated by a tuple: (paragraph nr., sentence nr., word in a sentence nr.).</p> <p>One possible approach would be to generate paragraphs, for each paragraph to generate sentences, and for each sentence to generate words.</p> <p>Ex. text:</p> <p>\"\"\" All the world's a stage, And all the men and women merely players; They have their exits and their entrances, And one man in his time plays many parts, His acts being seven ages.  At first, the infant, Mewling and puking in the nurse's arms.</p> <p>Then the whining schoolboy, with his satchel And shining morning face, creeping like snail Unwillingly to school.  And then the lover, Sighing like furnace, with a woeful ballad Made to his mistress' eyebrow.  Then a soldier, Full of strange oaths and bearded like the pard, Jealous in honor, sudden and quick in quarrel, Seeking the bubble reputation Even in the cannon's mouth.  And then the justice, In fair round belly with good capon lined, With eyes severe and beard of formal cut, Full of wise saws and modern instances; And so he plays his part.  The sixth age shifts Into the lean and slippered pantaloon, With spectacles on nose and pouch on side; His youthful hose, well saved, a world too wide For his shrunk shank, and his big manly voice, Turning again toward childish treble, pipes And whistles in his sound.  Last scene of all, That ends this strange eventful history, Is second childishness and mere oblivion, Sans teeth, sans eyes, sans taste, sans everything. \"\"\"</p> <p>All the Worlds a Stage by William Shakespeare  (at least this is what, the website where I found it, claims).</p> <p>For example, a start of a solution can be:</p> <pre><code>def paragprahs(text):\nyield from text.split(\"\\n\\n\")\nfor paragraph in paragprahs(text):\nprint(paragraph)\nprint('-' * 20)\n</code></pre> <p><code>(output omitted)</code></p> <p>yield from is a short-hand for a loop over the iterator (a list in this case) and yielding each of the elements. This is different from returning the list itself. With 'yield from' we are returning a generator that can be iterated on only once. In a way, the list that was created by the call to 'split' can be garbage collected when the generator returned by paragraphs is exhausted. If we returned the list, the caller may still keep a reference to the list somewhere and hence the list may have been kept \"alive\" in memory.</p>"},{"location":"part_IX_pytest_black_flake8/","title":"Part IX","text":"<p>We'll talk here about various tools that help us further in building good software.</p>"},{"location":"part_IX_pytest_black_flake8/#pytest","title":"Pytest","text":""},{"location":"part_IX_pytest_black_flake8/#black","title":"Black","text":""},{"location":"part_IX_pytest_black_flake8/#flake8","title":"Flake8","text":""},{"location":"part_VIII_ecosystem_and_packaging/","title":"Part VIII - Ecosystem and Packaging","text":"<p>We've seen already the concept of a module, from Python's standard library, or one from a package that we've installed in our environment. Also related concept is a \"namespace\". Let's try to make some sense with those concepts.</p>"},{"location":"part_VIII_ecosystem_and_packaging/#modules","title":"Modules","text":"<p>A module is a (Python) file containing Python code. As simple as that. We can import a module from another module. We can execute a module as a script from the command line.</p> <pre><code>python my_app.py\npython -m my_app\n</code></pre> <p>We often have multiple modules (Python files). We'll make our life easier by organizing those into directories (Operating-System folders). When we have a directory (and potentially subdirectories) with Python files (modules), this is getting closer to become a Python package. </p> <p>To make it into a package, what is left is to introduce __init__.py in each directory. The __init__.py file is often empty, yet it is still required.</p> <pre><code>import pandas as pd\nfrom numpy.random import * # please avoid\nfrom tqdm import tqdm # okay\n</code></pre> <p>Above we have imported the module 'pandas' and gave it the short-hand convention 'pd'. In our namespace we've added the symbol 'pd' that happens to be a module.</p> <p>Then we've imported from the (sub)module numpy.random everything that is available. Using an asterisk is not recommended as we've lost track of what we've brought, and we'll confuse ourselves and our friends with referring to items that we don't remember from which module they are. In a quick, temporary, notebook session, you are welcome to use this \"fetch all\" import.</p> <p>The last example with 'tqdm', is actually okay. The custom is to import the module, as we've done with 'pd' and to refer to classes and functions by adding (note the dot) 'pd.' in front of them, for example <code>pd.DataFrame()</code>. If you know that you only need one specific thing out of the module, and you know that the name of the functionality you are using is self-explanatory, then, at least by my standards, this is okay. 'tqdm' is a useful utility to see progress bar:</p> <pre><code>a = 0\nfor _ in tqdm(range(100)):\na = (a + 1) * 2\n</code></pre> <pre><code>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:00&lt;00:00, 1181494.08it/s]\n</code></pre> <p>Just a recap. Note the addition of 'pd' to the items in the namespace.</p> <pre><code>import pandas as pd\nprint(dir())\n</code></pre> <p><code>['__annotations__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'pd']</code></p> <p>When we install a package, the relevant files are added to our Python environment. There they can be found by the Python execution-time, and also by our development tools to provide tips and completions.</p> <p>So a package is just a collection of modules. Another interpretation is that while we import modules in our Python code, (or some functionality from a module), we install packages (that bring with them modules). It is okay to confuse a little between those terms.</p>"},{"location":"part_VIII_ecosystem_and_packaging/#installable-packages","title":"Installable Packages","text":"<p>As mentioned already above, a package is a standard way to wrap modules and additional relevant files, add some metadata, and publish the work (internally or Open Source), to be available to consumption (installation).</p> <p>A package often have dependencies. Our package shall not contain a copy of the modules from packages that we want to use, but rather indicate the need for those packages. When we install, for example with pip (package installer for Python), conda, or maybe poetry, the tool (say pip) shall fetch the dependencies for example from pypi.org</p> <pre><code>pip install numpy\n</code></pre> <p>Above we've installed the package 'numpy'. The module 'numpy' share the name with its package. It is not always the case that the module has the same name as the relevant package. For example:</p> <pre><code>pip install opencv-python\n</code></pre> <p>But then:</p> <pre><code>import cv2\n</code></pre> <p>A library is a cross-language, or maybe OS-related, concept, that means about the same as a package. For example, if you install a Python package for computer vision, or for graphics, it may bring with it, additional libraries, that are needed (and were for example developed in C++ and compiled/linked into an installable OS library.)</p> <p>If you happen to \"accidently\" refer to a package as a 'library', no harm was done.</p> <p>Packages have versions. This is a way to indicate progress, compatibility, changes in the interface. When you use a package (install it in your environment, or add it as a dependency of your code), you can indicate that you are okay with the \"latest and greatest\", or that you actually need a specific version.</p> <p>The version is a string with a trivial \"lexicographic\" order interpretation.</p> <pre><code>pip show pandas\n</code></pre> <pre><code>Name: pandas\nVersion: 1.5.3\nSummary: Powerful data structures for data analysis, time series, and statistics\nHome-page: https://pandas.pydata.org\nAuthor: The Pandas Development Team\nAuthor-email: pandas-dev@python.org\nLicense: BSD-3-Clause\nLocation: /home/oren/projects/yapy3c/venv/lib/python3.8/site-packages\nRequires: python-dateutil, numpy, pytz\nRequired-by:\n</code></pre> <p>One option to \"dive\" deeper and see the dependencies versions:</p> <pre><code>pip install johnnydep\n\njohnnydep pandas\n</code></pre> <pre><code>2023-03-27 12:57:53 [info     ] init johnnydist                [johnnydep.lib] dist=pandas parent=None\n2023-03-27 12:57:55 [info     ] init johnnydist                [johnnydep.lib] dist=numpy&gt;=1.20.3 parent=pandas\n2023-03-27 12:57:59 [info     ] init johnnydist                [johnnydep.lib] dist=python-dateutil&gt;=2.8.1 parent=pandas\n2023-03-27 12:58:00 [info     ] init johnnydist                [johnnydep.lib] dist=pytz&gt;=2020.1 parent=pandas\n2023-03-27 12:58:01 [info     ] init johnnydist                [johnnydep.lib] dist=six&gt;=1.5 parent=python-dateutil&gt;=2.8.1\nname                        summary\n--------------------------  -----------------------------------------------------------------------\npandas                      Powerful data structures for data analysis, time series, and statistics\n\u251c\u2500\u2500 numpy&gt;=1.20.3           Fundamental package for array computing in Python\n\u251c\u2500\u2500 python-dateutil&gt;=2.8.1  Extensions to the standard Python datetime module\n\u2502   \u2514\u2500\u2500 six&gt;=1.5            Python 2 and 3 compatibility utilities\n\u2514\u2500\u2500 pytz&gt;=2020.1            World timezone definitions, modern and historical\n</code></pre> <p>Also useful <code>pip freeze | grep pandas</code> or any other package you're interested to find the current installed version.</p>"},{"location":"part_VIII_ecosystem_and_packaging/#virtual-environments","title":"Virtual Environments","text":"<p>We keep installing stuff, how do we know that we don't break previous functionality that we had with other projects? It is a good practice to have a separate Python environment for different projects. You can use for each of the environments even a different Python version. When you create the environment, you should use the \"right\" Python version. Then you activate the environment and you have some protection against breaking the installation of other projects, and that you or someone else break your installation.</p> <p>There are multiple tools to achieve above. 'Poetry' and 'Conda' among others. If no specific preference, try first the standard 'venv' module:</p> <pre><code>python3 -m venv venv\n</code></pre> <p>Here we choose the name 'venv' to our newly created virtual environment.</p> <p>On Linux (bash), we would then do:</p> <pre><code>source ./venv/bin/activate\n</code></pre> <p>And one can verify the (bash) environment variable:</p> <pre><code>env | grep VIRTUAL\n</code></pre> <p><code>VIRTUAL_ENV=/home/oren/projects/yapy3c/venv</code></p> <pre><code>tree -L 1 venv\n</code></pre> <pre><code>venv\n\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 bin\n\u251c\u2500\u2500 etc\n\u251c\u2500\u2500 include\n\u251c\u2500\u2500 lib\n\u251c\u2500\u2500 lib64 -&gt; lib\n\u251c\u2500\u2500 pyvenv.cfg\n\u2514\u2500\u2500 share\n</code></pre> <pre><code>which pip\n</code></pre> <p><code>/home/oren/projects/yapy3c/venv/bin/pip</code></p> <pre><code>ls venv/lib/python3.8\n</code></pre> <p><code>site-packages</code></p> <p>On Windows (PS):</p> <pre><code>.\\env\\Scripts\\activate\n</code></pre> <p>Verify (PS)</p> <pre><code>dir env: | out-string -stream | select-string VIRTUAL\n</code></pre> <pre><code>_OLD_VIRTUAL_PATH              C:\\Python310\\Scripts\\;C:\\Python310\\;C:\\Perl64\\bin;C:\\Users\\zbenm\\AppData\\Roaming\\Acti...\nVIRTUAL_ENV                    C:\\Users\\zbenm\\projects\\sols_challenge\\env\n</code></pre> <p>We can then verify the version of Python, and the versions of our installed packages ('pip show' as above).</p> <pre><code>python --version\n</code></pre> <p><code>Python 3.10.8</code></p>"},{"location":"part_VIII_ecosystem_and_packaging/#version-control-repositories-probably-git","title":"Version Control Repositories (probably 'git')","text":"<p>I assume here that you are familiar with the concept of version control and that you are using git.</p> <p>Let's say I'm using Github, and want to work on a new project in Python, that shall use Flask.</p> <ul> <li> <p>I'll start by creating a new repository on Github. Alternatively one can just create a new local folder for the project, for example, <code>../projects/my_flask_based_web</code> and <code>git init</code> there.</p> </li> <li> <p>Let's continue with the Github example. When we create the new repository we're given the option to add a README.md file and .gitignore file. We'll add .gitignore and let Github know that we're planning to use Python.</p> </li> <li> <p>We'll clone our new Github repository under our \"projects\" directory.</p> </li> <li> <p>We'll change directory into the just cloned repository.</p> </li> <li> <p>It make sense now to have here a Python virtual environment. Alternatively one can \"share\" virtual environments among projects. It is up to you.</p> </li> <li> <p>We'll choose to create a new virtual environment.</p> </li> </ul> <pre><code>python3 -m venv venv\n</code></pre> <p>We're using here 'venv' (rather than the many other ways to create a virtual environment).</p> <p>Let's see what is the <code>git status</code>.</p> <p>Interesting enough the new directory 'venv' is not shown as a new directory. This is thanks to the contents of '.gitignore', if this is not the case for you, consider adding a line to your '.gitignore' with the directory with your virtual environment. We usually don't add the virtual environment to the git repository.</p> <ul> <li> <p>Let's make sure to activate now the virtual environment.</p> </li> <li> <p>We want to install, in the example, Flask. Instead of quickly <code>pip install Flask</code> let's create a new text file 'requirements.txt' and add one line \"Flask\". Then we can do:</p> </li> </ul> <pre><code>pip install -r requirements.txt\n</code></pre> <p>Let's check:</p> <pre><code>pip show Flask\n</code></pre> <p>For me is showed:</p> <pre><code>Name: Flask\nVersion: 2.2.3\nSummary: A simple framework for building complex web applications.\nHome-page: https://palletsprojects.com/p/flask\nAuthor: Armin Ronacher\nAuthor-email: armin.ronacher@active-4.com\nLicense: BSD-3-Clause\nLocation: /home/oren/projects/try_flask/venv/lib/python3.8/site-packages\nRequires: Jinja2, importlib-metadata, Werkzeug, click, itsdangerous\nRequired-by:\n</code></pre> <ul> <li> <p>remember to add 'requirements.txt` to the repository with <code>git add requirements.txt</code>. This text file we do want to keep.</p> </li> <li> <p>Now we need a flask application. We'll create for example, 'app.py' and add some contents from an example.</p> </li> </ul> app.py<pre><code>from flask import Flask, render_template\napp = Flask(__name__)\n@app.route(\"/&lt;name&gt;\")\ndef hello_world(name):\nreturn render_template('hello.html', name=name)\n</code></pre> templates/hello.html<pre><code>&lt;!doctype html&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;title&gt;Hello from Flask&lt;/title&gt; \n&lt;/head&gt;\n&lt;body&gt;\n{% if name %}\n  &lt;h1&gt;Hello {{ name }}!&lt;/h1&gt;\n{% else %}\n  &lt;h1&gt;Hello, World!&lt;/h1&gt;\n{% endif %}  \n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Please note that the installation of 'Flask' also added a command to our environment.</p> <pre><code>which flask\n</code></pre> <p>For me it is found here:</p> <p><pre><code>/home/oren/projects/try_flask/venv/bin/flask\n</code></pre> - Run the application.</p> <pre><code>flask --app app.py run\n</code></pre> <ul> <li>Now add all necessary files to git, then <code>git commit -m \"initial version\"</code> for example, (and potentially push to Github).</li> </ul> <p>We had only one Python module (the 'app.py' file). Nothing prevents us from adding additional modules that may be imported from 'app.py'. We can also add package requirements to 'requirements.txt' and issue again <code>pip install -r requirements.txt</code>.</p> <p>Static files and templates can also be created and added to the directory and to the git repository.</p> <p>When our colleagues want to have access to the project and potentially join the efforts, we give them a link to the Github repository. We also remind them that they need to install the required packages before trying the application. This can be documented also, for example, in the README.md file.</p> <p>Some of our colleagues will follow you, and do as follows:</p> <pre><code>python3 -m venv venv\npip install -r requirements.txt\n</code></pre> <p>Others may wish to work in their existing virtual environment (or even their global Python environment), and issue immediately:</p> <pre><code>pip install -r requirements.txt\n</code></pre> <p>Some may want to use other tools, for example, Poetry for the task.</p> <p>Note that since the virtual environment mechanism was not part of the repository, each of us can pick his/her favourite way.</p> <p>Also note that it is possible to share a single (git) repository among multiple projects. There are advantages for each way. For example, if each project has its own repository, the projects can advance each in its own pace. Less confusion and interdependencies. On the other way, if we have multiple (team related) projects in the same repository, then the team members are aware of each other work and can iteratively \"code review\", catch early miscommunications etc. </p> <p>It is up to the team to decide what works for the team the best.</p> <p>Each of us on his laptop could have a single Python virtual environment for all the projects, or a separate Python virtual environment in each project directory.</p> <p>Again, up to you to decide what makes sense in your settings and constraints.</p>"},{"location":"part_VIII_ecosystem_and_packaging/#publishing-a-package-rather-than-a-git-repository","title":"Publishing a package rather than a (git) repository","text":"<p>Above, \"trying Flask\", is a top-level project. Our \"sharing mechanism\" was the version control.</p> <p>There are projects that we want to allow others to install in their existing environments, so that they can import the functionality from our modules in their own code, without cloning our repository first, or maybe with cloning, but then without being part of the repository maintainers, but rather being \"users\" of our package.</p> <p>We're not far from achieving above. Let's have another project. This time our project, let's call it 'tiny', will be a utility package for the use of the previous \"trying Flask\" project, potentially also for additional projects.</p> <p>I've created a new git repository, intended for Python. I've created a new virtual environment and made sure it is activated and there is where I'm working.</p> <p>I've started the same, I have a 'requirements.txt' file in which I list 'numpy' as I know I'm going to use it next. I've installed the requirements with <code>pip install -r requirements.txt</code> and started to edit my 'tiny' package.</p> <p>The directory where I'm working (the git repository) is named 'tiny_package'. This is how I've named the new repository. But The actual modules I'll have under the (one level deeper) directory 'tiny'. My 'tiny' package shall accept variable number of arguments, and shall return a matching 'numpy array'. This is the functionality I'll introduce.</p> <p>Under the directory 'tiny' I'll have a Python module (a Python file) 'mat_math.py', and also the required '__init__.py'. Below is the content of the files:</p> tiny/mat_math.py<pre><code>import numpy as np\n\ndef to_numpy_arr(*args: int) -&gt; \"np.ndarray[int]\":\n    \"\"\"\n    This function takes a variable amount of argument and\n    returns the matching numpy array\n\n    &gt;&gt;&gt; to_numpy_arr(1, 2, 3)\n    array([1, 2, 3])\n    \"\"\"\n    return np.array(args)\n\nif __name__ == \"__main__\":\n    import doctest\n\n    doctest.testmod()\n</code></pre> tiny/__init__.py<pre><code>from .mat_math import to_numpy_arr\n\n__version__ = \"0.0.1\"\n\n__all__ = [\"to_numpy_arr\"]\n</code></pre> <p>I wanted to make 'to_numpy_arr' functionality available directly from the 'tiny' package. This is done with the '__all__' list variable. '__version__' will be linked and available also in the metadata of the package (see below in 'setup.cfg').</p> <p>I have a 'doctest' for the module. I have also added an \"external\" test. This external test will be added to the repository yet will not be included in the package.</p> test.py<pre><code>import tiny\n\ndef test1():\n    print(\"test1\")\n    assert tiny.to_numpy_arr(1, 7).sum() == 8\n    print(\"test1 passed\")\n\nif __name__ == \"__main__\":\n    test1()\n</code></pre> <p>We are almost there. We still need either 'setup.py' (the old way of packaging), or 'setup.cfg' + 'pyproject.toml' (a newer way to package). I've chosen the second way.</p> setup.cfg<pre><code>[metadata]\nname = tiny\nversion = attr: tiny.__version__\nauthor = Oren Zeev-Ben-Mordehai\nauthor_email = zbenmo@gmail.com\nurl = https://github.com/zbenmo/tiny_package\ndescription = for use in a tutorial\nlong_description = file: README.md\nlong_description_content_type = text/markdown\nkeywords = Reinforcement Learning, Framework, Integration\nlicense_files = LICENSE.txt\nclassifiers =\n    Intended Audience :: Developers\n    Intended Audience :: Science/Research\n    Programming Language :: Python :: 3\n    Programming Language :: Python :: 3.7\n    Programming Language :: Python :: 3.8\n    Programming Language :: Python :: 3.9\n    License :: OSI Approved :: MIT License\n    Topic :: Scientific/Engineering\n    Topic :: Scientific/Engineering :: Artificial Intelligence\n\n[options]\npackages = find:\nzip_safe = True\ninclude_package_data = True\ninstall_requires =\n    numpy\n\n[options.package_data]\n* = README.md\n</code></pre> pyproject.toml<pre><code>[build-system]\nrequires = [\n    \"setuptools&gt;=42\",\n    \"wheel\"\n]\n</code></pre> <p>I've issued the following command:</p> <pre><code>pip install -e .\n</code></pre> <p>This commands tells 'pip' to install the package from the current directory in \"development\" mode.</p> <p>If you got an error:</p> <pre><code>ERROR: File \"setup.py\" not found. Directory cannot be installed in editable mode: /home/oren/projects/tiny_package\n(A \"pyproject.toml\" file was found, but editable mode currently requires a setup.py based build.)\n</code></pre> <p>Issue: <code>pip install -U pip</code>, and try again <code>pip install -e .</code>.</p> <p>I've verified my external test with:</p> <pre><code>python test.py\n</code></pre> <p>Note: 'requirements.txt' is not needed any more here. We could have <code>pip uninstall numpy</code>, and <code>pip install -e .</code> would have brought 'numpy' again as it is a dependency of 'tiny' project. 'requirements.txt' can be removed from git if was previously added (here in the 'tiny_package' repository.). We do want to add to the repository 'test.py', 'setup.cfg', 'pyproject.toml', and the Python files.</p> <p>To build the package, we can use <code>pip install build</code> and issue <code>python -m build</code>. to publish the build package for example to 'pypi.org' we can use <code>pip install twine</code> and issue something like <code>python -m twine upload --repository pypi dist/*</code> (we'll need an account for this on 'pypi.org').</p> <p>We'll skip the build and the publishing. Instead we'll install the new 'tiny' package also in the other Python virtual environment used for playing with Flask.</p> <p>If you wish you can first commit the changes to the 'tiny_package' repository.</p> <p>Let's switch to the Python virtual environment used for the Flask experiments. We'll introduce a new dependency, a one of the 'tiny' package. Declaring the dependency should be done in 'requirements.txt' there. We'll make another shortcut for now.</p> <ul> <li> <p>While in the Python virtual environment of the Flask project, navigate to the directory with the 'tiny_package' repository.</p> </li> <li> <p>Make sure you do not activate the Python virtual environment there but are still with the virtual environment from the Flask project.</p> </li> <li> <p><code>pip install -e .</code> This will install the 'tiny' package now in the current Python virtual environment used for the Flask project.</p> </li> </ul> <p>In the Flask project, I've added the following \"endpoint\":</p> <pre><code>..\nimport tiny\n..\n@app.get('/try_tiny/&lt;int:first&gt;')\ndef try_tiny(first: int):\nret = list(tiny.to_numpy_arr(first, 2 * first, 3 * first))\nreturn list(map(int, ret))\n</code></pre> <p>The code receives an int, 'first' and returns a \"JSON\" list with 'first', 'first' multiplied by 2, and 'first' multiplied by 3.</p> <p>I needed to convert the 'numpy' array into a list, and the items to 'int' from 'numpy.int32' as the \"jsonify\" functionality does not know to work with 'numpy'.</p> <p>If you are using someone's else package, say an Open Source that is maintained in the example on Github, and you believe you've found a bug, you may attempt to solve it by:</p> <ul> <li> <p>Fork the Github repository of the package.</p> </li> <li> <p>Clone (your) relevant Github repository into your laptop.</p> </li> <li> <p><code>pip install -e .</code> in the just cloned repository (note you are using the Python virtual environment of your project).</p> </li> <li> <p>If all above succeeded you can now attempt to fix the bug.</p> </li> <li> <p>If you have a fix, add the changes and commit, then push to your Github repository, and open a PR.</p> </li> <li> <p>You now have to keep track of the status of that project / Python package. Your code is working, subject that the fix is present. You currently have the fix only in your clone of the original repository. Till it is accepted and updated on pypi.org, you have to keep working with your own copy. This delays also the availability of your project / package for others. You do have the option to require the specific point of the package, from the commit in your repository. Read more on Stack Overlow.</p> </li> </ul>"},{"location":"part_VIII_ecosystem_and_packaging/#a-few-words-on-packages-versions-and-dependencies","title":"A few words on packages' versions and dependencies","text":"<p>Our original project for experimenting with 'Flask' did not need 'numpy'. Let's keep it like that. The fact that 'tiny' brought with it 'numpy' is just fine. If in a future version 'tiny' will drop that dependency or upgrade the requirement to a higher 'numpy' version, that should not influence us.</p> <p>In 'tiny' we've just added a requirement to 'numpy' (any version). That is not a good practice. We've tested 'tiny' with a specific 'numpy' version, maybe with a previous version or with a future version, our code does not work?</p> <p>It is a good practice to require the specific version we've used. If I run <code>pip freeze | grep numpy</code> I get <code>numpy==1.24.2</code>. We should say that <code>numpy &gt;= 1.24.2, &lt; 1.25</code> should be okay. We've allowed more 'numpy' versions than the one we've used. '1.24.3' should also be okay according to our specification. There is a convention, that if a \"breaking change\" is introduced the version must be incremented in the second position.</p> <p>Remember that those are conventions and bugs can still crawl in. On the other hand, in many situations it is okay to be a bit \"lazy\" and just wait till someone complains. When this happens, check with the user of your package what 'numpy' he/she have in their Python virtual environment. Check yourself what happens when you have this 'numpy' version with your package, and decide what is the right remedy. </p> <p>What happens when your project needs <code>numpy &lt; 1.25</code> while a dependencie of your project, say 'pandas' needs <code>numpy &gt;= 1.26</code>? You'll have to investigate. Maybe you can allow also for 'numpy' version '1.26', potentially by modifying a little your code? Maybe the dependency 'pandas' has a previous version that can live with <code>numpy &lt; 1.25</code> and is still good for your project, then just require that version of the dependency 'pandas', for example (fictional) <code>pandas &gt;= 2.3.0, &lt; 2.3.6</code>. Sometimes it is more drastic and you'll need to break your project into two processes or use other packages. May the odds be ever in your favour.  </p> <p>In some situations, as of regulatory requirements, you may be asked to list all the dependencies of your software (Open Source and other) and the versions used. As far as I can tell, listing the top level of your dependencies is good enough (no need to follow dependencies of your dependencies, if I am not mistaken. Check that with your accompanying regulatory officer).</p>"},{"location":"part_VIII_ecosystem_and_packaging/#docker","title":"Docker","text":"<p>The last thing I want to bring here is a little philosophical. Most likely we'll all going to use Docker these days, that way or another. Does it mean that some of the mechanism above are redundant and we can decide not to make use of them?</p> <p>My feeling is that it is a good thing to have all above mechanisms and also Docker. Each mechnism helps us to \"wrap\" and \"isolate\" our development / deployment software in another layer of \"trust\". Each helps us achieve reproducability and reliability.</p> <p>When you have a Docker image, the image may have some Python functionality before you join with your software, tools, and processes. By introducing a Python virtual environment, you know that your code shall be happy, while the other things that happen in the containers are as the designer of the image / container wanted.</p> <p>You can give someone a Docker image, in which you've already installed the right Python packages and other dependencies. Then this user can run a container with your software and never worry about git repositories, Python packages, versions, dependencies, etc. You as the maintainer of the code, will most likely need from time to time to create a new version of the Docker image, and there you will be probably happier if you have the mechanisms above to keep your sanity.</p>"},{"location":"part_VII_pd/","title":"Part VII (pandas)","text":"<p>We'll talk about 'pandas' which is a very useful Python package that enables us to do Excel-like, or SQL-like, data manipulations in our code.</p> <p>Often one will have:</p> <pre><code>import numpy as np\nimport pandas as pd\n...\n</code></pre> <p>While 'pandas' dependents on 'numpy', 'numpy' is the linear algebra, matrix manipulations, and performance (vectorizing) considerations. 'pandas' is oriented toward the data-scientist. 'pandas' adds the \"tabular\" manipulation, filtering rows, merging tables, creating \"calculated columns\" and more.</p> <p>To create a dataframe one needs values that can fit into rows / columns table. For example we can assemble a dataframe with a dict where the keys are the \"columns\" and the values are lists with matching values. The lists should be of the same length.</p> <pre><code>df = pd.DataFrame({\n'name': ['Jan', 'Oren', 'Michael'],\n'age': [30, 20, 40]\n}); df.shape\n</code></pre> <p><code>(3, 2)</code></p> <pre><code>df\n</code></pre> name age 0 Jan 30 1 Oren 20 2 Michael 40 <p>Note that a 'pandas' dataframe has two indices, the columns index <code>df.columns</code>, and the rows index <code>df.index</code>.</p> <pre><code>df.columns, df.index\n</code></pre> <pre><code>(Index(['name', 'age'], dtype='object'), RangeIndex(start=0, stop=3, step=1))\n</code></pre> <p>An alternative can be to assemble a dataframe from \"records\" with the same structure.</p> <pre><code>def records():\nfor i in range(5):\nyield (i + 1,  i + ord('a'), 90 - i, 3 ** i)\npd.DataFrame.from_records(records(), columns=['c1','c2','c3', 'c4'])\n</code></pre> c1 c2 c3 c4 0 1 97 90 1 1 2 98 89 3 2 3 99 88 9 3 4 100 87 27 4 5 101 86 81 <p>We can also initialize a dataframe from 'numpy' 2d-array:</p> <pre><code>df_from_np_matrix = pd.DataFrame(np.random.randn(8, 5), columns=list(\"ABCDE\"))\ndf_from_np_matrix\n</code></pre> A B C D E 0 -0.796475 1.094937 0.085857 -0.422669 0.838842 1 0.193157 1.581320 -0.154880 -0.072739 0.124116 2 1.602135 0.443397 -1.886092 0.763741 -0.094495 3 -1.904237 -0.075916 -0.160738 0.189941 2.368079 4 -0.556937 0.989280 0.137683 1.488743 -0.647949 5 1.350182 -0.297231 0.854884 -0.344520 -0.129298 6 -1.392316 -2.541472 0.680830 1.210426 -1.091972 7 -0.525120 0.421930 1.668550 0.260011 1.383353 <p>And of course, a lot of time we'll load a CSV file or a result of an SQL query from a database.</p> <pre><code>import pandas as pd\nfrom pathlib import Path\ntrain_path = Path(\"data/train\")\ndf = pd.read_csv(train_path / \"train.csv\"); df.shape\n</code></pre> <p><code>(13000, 28)</code></p> <p>In a notebook, we'll often examine the \"head\" of the dataframe.</p> <pre><code>df.head()\n</code></pre> id categoryA categoryB categoryC categoryD categoryE categoryF featureA featureB featureC featureD featureE featureF featureG featureH featureI compositionA compositionB compositionC compositionD compositionE compositionF compositionG compositionH compositionI compositionJ unit result 0 a563699ca2a601c6ac64aa29986a00a90fb42b48741695b0526a286d504d17ca catA_1 catB_0 catC_718 catD_0 catE_0 catF_0 75808.375 4.457840 0.005718 122.299437 30.831906 0.0 2.806036e+12 0.000000 71176346.0 0.0 10.0 26.0 0.0 32.0 3.0 0.0 9.0 22.26 20.0 unit_6 0.000458 1 91ab3eb3bcf6c8c1c5fe2da9ba671aa5a48c7369d9a50f32e1ddd735472b4b3c catA_1 catB_0 catC_1309 catD_0 catE_0 catF_0 75808.375 4.457840 0.005718 122.299437 30.831906 0.0 2.806036e+12 0.000000 71176346.0 0.0 10.0 26.0 0.0 32.0 3.0 0.0 9.0 22.26 20.0 unit_6 0.000335 2 7128c51c554735d6c81862684ad6005ae12d2edbcd464487a7217fc72c03ba22 catA_15 catB_0 catC_1309 catD_0 catE_0 catF_0 75808.375 4.457840 0.005718 122.299437 30.831906 0.0 2.806036e+12 0.000000 71176346.0 0.0 10.0 26.0 0.0 32.0 3.0 0.0 9.0 22.26 20.0 unit_4 0.054072 3 c8144b52e4f63014de0a0d8e1c629bf0b05cb2696cfc23291b4f48e6491c4cb5 catA_0 catB_0 catC_935 catD_0 catE_0 catF_0 75808.375 4.457840 0.005718 122.299437 30.831906 2.0 2.806036e+12 0.000000 71176346.0 0.0 10.0 26.0 0.0 32.0 3.0 0.0 9.0 22.26 20.0 unit_5 0.061143 4 88d15a5b2df6692f23d105ff1ae82ae026be00c9271eef33e0aea97fd2110cb6 catA_22 catB_0 catC_1325 catD_0 catE_2 catF_0 -40055.250 4.363288 0.729194 93.677197 15.047884 4.0 1.464509e+12 87.158924 50941692.0 0.0 8.0 14.0 0.0 49.0 3.0 2.0 9.0 16.84 15.0 unit_15 0.015439 <p>The columns of a dataframes are series. Each column (serie) has its data type. We can have a quick summary of the dataframe with:</p> <pre><code>df.info()\n</code></pre> <pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 13000 entries, 0 to 12999\nData columns (total 28 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   id            13000 non-null  object \n 1   categoryA     13000 non-null  object \n 2   categoryB     13000 non-null  object \n 3   categoryC     13000 non-null  object \n 4   categoryD     13000 non-null  object \n 5   categoryE     13000 non-null  object \n 6   categoryF     13000 non-null  object \n 7   featureA      12936 non-null  float64\n 8   featureB      12936 non-null  float64\n 9   featureC      12936 non-null  float64\n 10  featureD      12936 non-null  float64\n 11  featureE      12936 non-null  float64\n 12  featureF      13000 non-null  float64\n 13  featureG      12936 non-null  float64\n 14  featureH      12936 non-null  float64\n 15  featureI      12936 non-null  float64\n 16  compositionA  12936 non-null  float64\n 17  compositionB  12936 non-null  float64\n 18  compositionC  12936 non-null  float64\n 19  compositionD  12936 non-null  float64\n 20  compositionE  12936 non-null  float64\n 21  compositionF  12936 non-null  float64\n 22  compositionG  12936 non-null  float64\n 23  compositionH  12936 non-null  float64\n 24  compositionI  12936 non-null  float64\n 25  compositionJ  12936 non-null  float64\n 26  unit          13000 non-null  object \n 27  result        13000 non-null  float64\ndtypes: float64(20), object(8)\nmemory usage: 2.8+ MB\n</code></pre> <p>When 'matplotlib' is available (installed in the Python virtual environment), the following shall produce a plot.</p> <pre><code>df.featureA.plot(kind=\"hist\", bins=20);\n</code></pre> <p></p> <p>Also very convenient:</p> <pre><code>df.unit.value_counts()\n</code></pre> <pre><code>unit_0     2548\nunit_1     1618\nunit_2     1004\nunit_3      993\nunit_4      962\nunit_6      853\nunit_5      840\nunit_7      787\nunit_8      740\nunit_9      668\nunit_10     589\nunit_11     455\nunit_12     348\nunit_13     269\nunit_14     164\nunit_15      96\nunit_16      55\nunit_17       7\nunit_18       4\nName: unit, dtype: int64\n</code></pre> <p>When we create a \"new\" dataframe from an existing one, a lot of times, we're still sharing the cells' memory. Often this is exactly what we want to avoid the extra cost in memory and performance. Just need to be aware of it, to avoid surprises. If needed, one can always 'copy'.</p> <pre><code>df\n</code></pre> name age 0 Jan 30 1 Oren 20 2 Michael 40 <pre><code>df_head = df.head(2)\ndf_head\n</code></pre> name age 0 Jan 30 1 Oren 20 <pre><code>df_head.loc[0, 'age'] = 31\ndf_head\n</code></pre> name age 0 Jan 31 1 Oren 20 <pre><code>df\n</code></pre> name age 0 Jan 31 1 Oren 20 2 Michael 40"},{"location":"part_VII_pd/#groupby","title":"Groupby","text":"<p>With 'pandas' we can collect statistics about specific columns. It is also interesting to collect the statistics per value in another columns. For example, collect the survival rate (Titanic) based on gender, or on travel class. Such group based statistics is very useful in data analysis and also in ML, potentially helping the model in picking the relevant information from a categorical feature (ex. the gender, the travel class), this is called target encoding. Special care needs to be taken to verify the target encoding actually helps or causing overfitting, this should be evaluated case by case.</p> <p>To get the per group statistics we use the 'df.groupby' functionality. The return type of 'groupby' on a dataframe is a 'DataFrameGroupBy'. This class allows iterating over \"sub-dataframes\", one per group, or also aggragating statistics per group.</p> <pre><code>df = pd.DataFrame(\n{\n\"animal\": \"cat dog cat fish dog cat cat\".split(),\n\"size\": list(\"SSMMMLL\"),\n\"weight\": [8, 10, 11, 1, 20, 12, 12],\n\"adult\": [False] * 5 + [True] * 2,\n}\n)\ngb = df.groupby([\"animal\"])\ngb.get_group(\"cat\")\n</code></pre> animal size weight adult 0 cat S 8 False 2 cat M 11 False 5 cat L 12 True 6 cat L 12 True <p>Above example is taken from Pandas Cookbook - Grouping</p> <p>Not specific about 'groupby', but contains also 'groupby' examples and other good Pandas / Notebooks best practices: Vincent D. Warmerdam: Untitled12.ipynb | PyData Eindhoven 2019</p>"},{"location":"part_VII_pd/#tidy-data","title":"Tidy data","text":"<p>We often get the data in somewhat different arrangement from what we would like to have for our data analysis, building ML models, etc. The data is given \"wide\" while we actually want it to be \"long\", or the other way around. To change the arrangement into what we need, may seem at first to be more sort-of an art than a science. However there are actually many things that we do see often and for which there exist a collection of formulas that are worth to get familiar with.</p> <p>I will bring here for example a dataset I have played with in the past (Mammals). The dataset is given as a table. In the table Europe is divided into cells and for each cell one can see what mammals can be found in that cell. Each row in the table is about a specific cell. There are columns of three types, columns about the cell, columns related to conditions in the cell per-month (rain, temperatures, etc.), and binary colunms per mammal (presence).</p> <p>Wrote a Medium article about it mammals-dataset-tidy-data And the relevant github link is mammals - Github</p> <p>A quick summary of the steps taken there (Mammals dataset):</p> <ul> <li>Split the data into three tables, metadata about a cell, bio-climate features per-month about the cell, mammals-presence info about cells.</li> <li>'melting' columns that actually contain information. Example 'mean_temp_feb_utm' columns was now a value under column 'variable', and next to the original value which is under the column 'value'.</li> <li>Spliting the values where needed into new columns. For example split 'mean_temp_feb_utm' from the 'variable' columns to the the values 'mean_temp' and 'feb_utm' under the columns 'statistics', 'month', respectively.</li> <li>pivoting the relevant values back into columns and values in those columns. For example, there should be a column called 'month' and having the relevant values, ex. 'feb_utm', and there should be columns of the bio-climate features, ex. 'mean_temp' with the matching values.</li> <li>We can then merge back tables as needed, for example I demonstrate there counting how many different mammal types are per cell, and showing that in a \"map\". </li> </ul> <p>Strongly recommend the following PyData YouTube-recorded talk Daniel Chen: Cleaning and Tidying Data in Pandas | PyData DC 2018.</p>"},{"location":"part_VII_pd/#experimenting-with-k-folds","title":"Experimenting with k-folds","text":"<p>When we use supervised learning, for example, in machine learning (ML) setting. We'll most likely want to verify the quality of our model on some left aside \"training samples\". We'll call those the \"evaluation set\" or also known as \"test set\". A common practice is for example, to keep 30% of the cases for evaluation, and train of the other 70%  (train / test split). It is recommended to select the data points for the evaluation set randomly.</p> <p>If we can afford the time, it might even better to repeat the experiment a few times, each time selecting a different evaluation set and training on all the other data points. For example we can take each time another 20% of the cases and train on the rest 80%, and repeat that 5 times so that each data point was 4 times in a training set, and 1 time in the test set. This setting is called cross validation.</p> <p>We often use the 'scikit-learn' for exploratory data analysis (EDA) and for ML modeling. 'scikit-learn' contains also functions and classes that help with preprocessing, model selection and evaluation, and related tasks. The packages 'pandas' and 'scikit-learn' work well together. For example the following will prepare for us a \"train / test split\".</p> <p>Remember to add 'scikit=learn' to your 'requirements.txt', followed by <code>pip install -r requirements.txt</code>, or just install it directly with for example <code>pip install scikit=learn</code>. </p> <pre><code>import pandas as pd\nimport numpy as np\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.model_selection import train_test_split\nX, y = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=True)\nX.shape, y.shape\n</code></pre> <pre><code>((1309, 13), (1309,))\n</code></pre> <pre><code>X.info()\n</code></pre> <pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1309 entries, 0 to 1308\nData columns (total 13 columns):\n #   Column     Non-Null Count  Dtype   \n---  ------     --------------  -----   \n 0   pclass     1309 non-null   float64 \n 1   name       1309 non-null   object  \n 2   sex        1309 non-null   category\n 3   age        1046 non-null   float64 \n 4   sibsp      1309 non-null   float64 \n 5   parch      1309 non-null   float64 \n 6   ticket     1309 non-null   object  \n 7   fare       1308 non-null   float64 \n 8   cabin      295 non-null    object  \n 9   embarked   1307 non-null   category\n 10  boat       486 non-null    object  \n 11  body       121 non-null    float64 \n 12  home.dest  745 non-null    object  \ndtypes: category(2), float64(6), object(5)\nmemory usage: 115.4+ KB\n</code></pre> <pre><code>train_X, validation_X, train_y, validation_y = (\ntrain_test_split(X, y, test_size=0.3, stratify=y, random_state=1)\n)\ntrain_X.shape, validation_X.shape\n</code></pre> <pre><code>((916, 13), (393, 13))\n</code></pre> <p>Thanks to the usage of 'stratify' with the target 'y', we have about the same ratio of survived to did-not survive in the train set and in the validation set.</p> <pre><code>(\ntrain_y.value_counts(normalize=True),\n'-' * 40,\nvalidation_y.value_counts(normalize=True)\n)\n</code></pre> <pre><code>(0    0.617904\n 1    0.382096\n Name: survived, dtype: float64,\n '----------------------------------------',\n 0    0.618321\n 1    0.381679\n Name: survived, dtype: float64)\n</code></pre> <p>For cross validation setting, one can either use 'cross_val_score', letting the function run the cross validation experiment and return the final evaluation metrics as in:</p> <pre><code>scores = cross_val_score(clf, X, y, cv=5)\n</code></pre> <p>And you get a 'numpy' array with (5 in this case) results.</p> <p>Another way to a achieve a cross validation split, is with the class 'StratifiedKFold'.</p> <pre><code>from sklearn.model_selection import StratifiedKFold\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\nfor fold, (train_index, validation_index) in enumerate(skf.split(X, y)):\nprint(f\"Fold {fold}:\")    \nprint(y[validation_index].value_counts())\nprint()\n</code></pre> <pre><code>Fold 0:\n0    162\n1    100\nName: survived, dtype: int64\n\nFold 1:\n0    162\n1    100\nName: survived, dtype: int64\n\nFold 2:\n0    162\n1    100\nName: survived, dtype: int64\n\nFold 3:\n0    162\n1    100\nName: survived, dtype: int64\n\nFold 4:\n0    161\n1    100\nName: survived, dtype: int64\n</code></pre> <p>Here is an idea, taken from Approaching (Almost) Any Machine Learning Problem by Abhishek Thakur.</p> <p>Most likely we'll want to compare various ML model classes and models as to find the one that gives best desired results on the validation set. Potentially use different environments, programming languages, and libraries. Let's start by fixing the fold for each data point. We'll save the data with the new column added. This can be used later in any future experiment.</p> <pre><code>X['kfold'] = -1\nfor fold, (train_index, validation_index) in enumerate(skf.split(X, y)):\nX.loc[validation_index, 'kfold'] = fold\n# Here we'll save the dataframe for future usages. Assume we have done so. \nX.kfold.value_counts()\n</code></pre> <pre><code>3    262\n2    262\n1    262\n0    262\n4    261\nName: kfold, dtype: int64\n</code></pre> <p>When we want to do a cross validation experiment, we'll rely on the presense of the 'kfold' columns:</p> <pre><code>for fold in range(5):\ntrain_X = X.loc[lambda d: d['kfold'] != fold]\nvalidation_X = X.loc[lambda d: d['kfold'] == fold]\nprint(f\"Fold {fold}:\")    \nprint(train_X.shape, validation_X.shape)\nprint()\n</code></pre> <pre><code>Fold 0:\n(1047, 14) (262, 14)\n\nFold 1:\n(1047, 14) (262, 14)\n\nFold 2:\n(1047, 14) (262, 14)\n\nFold 3:\n(1047, 14) (262, 14)\n\nFold 4:\n(1048, 14) (261, 14)\n</code></pre>"},{"location":"part_VI_various/","title":"Part VI","text":"<p>We'll walk here quickly on some additional Python constructs that weren't introduced before.</p>"},{"location":"part_VI_various/#args-and-kwargs","title":"'args' and 'kwargs'","text":"<p>A function may have positional parameters and named parameters. The named parameters have each a default, and hence can be omitted in a call. It is important to provide all the positional arguments first (to the left most), and then one can give any named argument that should get a different value from the default declared in the function definition to the matching parameter.</p> <pre><code>def my_func(p1, p2, named1=4, named2=7):\nprint(p1 + p2 + named1 + named2)\nmy_func()\n</code></pre> <pre><code>---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[40], line 1\n----&gt; 1 my_func()\n\nTypeError: my_func() missing 2 required positional arguments: 'p1' and 'p2'\n</code></pre> <pre><code>my_func(1, 2, 3)\n</code></pre> <p><code>13</code></p> <pre><code>my_func(1, 2, named2=3)\n</code></pre> <p><code>10</code></p> <p>A function may have a variable number of parameters. One way to achieve this is by actually having a list as a parameter, and documenting to the user of the function that he/she are expected to pass a list of values.</p> <pre><code>def count_characters(header, list_of_texts):\n\"\"\"This function returns the total number of characters in the texts you pass in 'list_of_texts'.\n    Note, you're expected to pass a list where the items are the individual texts\n    'header' is used in the output\"\"\"\nreturn f'{header}: {sum(len(x) for x in list_of_texts)}'\ncount_characters(\"Summary count\", [\"Hi\", \"Bye\"])\n</code></pre> <p><code>'Summary count: 5'</code></p> <p>There is a nicer Pythonic way to acchieve above.</p> <pre><code>def count_characters2(header, *list_of_texts):\n\"\"\"This function returns the total number of characters in the texts you pass.\n    'header' is used in the output\"\"\"\nreturn f'{header}: {sum(len(x) for x in list_of_texts)}'\ncount_characters2(\"Summary count\", \"Hi\", \"Bye\")\n</code></pre> <p><code>'Summary count: 5'</code></p> <p>Starting from the asterisk '*', the non-named arguments are collected into list_of_texts as a list. Note that the functions are similar and the only difference is the function declaration. The call to the function is then somewhat simpler. We've seen a similar call with 'print' for example.</p> <p>If we want to pass a variable number of named arguments, potentially some that our function shall only forward to another function, we can pass them in a dict. Again, Python provides a nice way to achieve that. This time we'll be using '**'.</p> <pre><code>def count_characters3(*list_of_texts, **kwargs):\n\"\"\"This function returns the total number of characters in the texts you pass.\n    'header' is used in the output\"\"\"\nheader = kwargs.get(\"header\", \"Count\")\nreturn f'{header}: {sum(len(x) for x in list_of_texts)}'\ncount_characters3(\"Hi\", \"Bye\", header=\"Summary count is still\")\n</code></pre> <p><code>'Summary count is still: 5'</code></p> <p>The names args and kwargs are commonly used for those parameters ('args' and 'keyword args'). Sometimes we'll use a specific name, as was in the example for list_of_texts. </p>"},{"location":"part_VI_various/#closure","title":"Closure","text":"<p>A closure is an object that is not a result of a class initialization, but rather a scope of execution that is being \"kept\" for later. For example.</p> <pre><code>def standardize(mean, std):\n\"\"\"\n    This function returns a function that accepts a number\n    and returns the standardized equivalent.\n    \"\"\"\ndef do_standardize(number):\nreturn (number - mean) / std\nreturn do_standardize\nfor std_fn in [standardize(1, 0.5), standardize(0, 1)]:\nprint(tuple(std_fn(arg) for arg in [1, 2, -1]))\n</code></pre> <pre><code>(0.0, 2.0, -4.0)\n(1.0, 2.0, -1.0)\n</code></pre> <p>In above example the object that we refer to as the closure is a function that has the context of mean and of std. This function object when called with a single argument, arg -&gt; number in the example, returns the standardized equivalent, taking into account mean and std. Above this was demonstrated with two such standardization function objects that, and for each of those we checked the returned value for 1, 2, and -1.</p> <p>Why is it nice to have this support in the language? It may be nice not to have to pass repetitive parameters on every call. In the example, we pass once mean and std and then forget about them. If we have two different standardization settings, then we have two relevant function objects, and again in the reset of the function we just use the right standardization object.</p> <p>There is a very useful util function, patrial in functools that would have help us achieve a similar \"keep for later\", if the mean and std where given as keyword args:</p> <pre><code>from functools import partial\ndef standardize(number, mean=0, std=1):\nreturn (number - mean) / std\nfor std_fn in [\npartial(standardize, mean=1, std=0.5),\npartial(standardize, mean=0, std=1)\n]:\nprint(tuple(std_fn(arg) for arg in [1, 2, -1]))\n</code></pre> <pre><code>(0.0, 2.0, -4.0)\n(1.0, 2.0, -1.0)\n</code></pre> <p>Here is another example for a potential usage of a closure. We want to count how many times we call specific functions in our program. We are aware of profiling \"debugging\" tools, yet we want to have it simply in our code. Something like the following:</p> <pre><code>def f1(a, b):\nreturn a + b\ndef f2(a, b, c):\nreturn a + b * c\ndef count_activation_f1():\n\"Helper to count activations of f1\"\ndef wrapped_f1(a, b):\nwrapped_f1.count += 1\nreturn f1(a, b)\nwrapped_f1.count = 0\nreturn wrapped_f1\nwrapped_f1 = count_activation_f1()\ndef count_activation_f2():\n\"Helper to count activations of f2\"\ndef wrapped_f2(a, b, c):\nwrapped_f2.count += 1\nreturn f2(a, b, c)\nwrapped_f2.count = 0\nreturn wrapped_f2\nwrapped_f2 = count_activation_f2()\nfor i in range(4):\nwrapped_f1(i, 3 * i + 1)\nfor i in range(42):\nwrapped_f2(i, 3 * i + 1, 5)\nwrapped_f1.count, wrapped_f2.count\n</code></pre> <pre><code>(4, 42)\n</code></pre>"},{"location":"part_VI_various/#function-decorators","title":"Function Decorators","text":"<p>In Python there is a nice way to achieve above. It is called function decorator. The code above can be written as follows.</p> <pre><code>def counted(f):\ndef wrapped(*args, **kwargs):\nwrapped.calls += 1\nreturn f(*args, **kwargs)\nwrapped.calls = 0\nreturn wrapped\n@counted\ndef f1(a, b):\nreturn a + b\n@counted\ndef f2(a, b, c):\nreturn a + b * c\nfor i in range(4):\nwrapped_f1(i, 3 * i + 1)\nfor i in range(42):\nwrapped_f2(i, 3 * i + 1, 5)    \nf1.calls, f2.calls\n</code></pre> <p><code>(4, 42)</code></p> <p>Note that counted can be used as a utility function decorator in additional places, and that we're making use of 'args' and '*kwargs' that were mentioned above. We add here that in order to pass those further to a function that expects the individual parameters, we also use '*' and '**' in the call (line 4).</p> <p>There is a small observation that we need to pay attention to.</p> <pre><code>@counted\ndef f3(x, y, a):\n\"\"\"This functions returns the 'mixture' of 'x' and 'y',\n    'a' parts 'x' and (1 - a) 'y'\"\"\"  \nassert 0 &lt;= a &lt;= 1 # yes we can do that in Python\nreturn x * a + y * (1 - a)\nprint(f3.__doc__)\n</code></pre> <p><code>None</code></p> <p>What just happened? Where is our docstring?</p> <p>'f3' is not anymore what we think it is. 'f3' is \"wrapped\". To \"fix\" that we can do, for example, as follows (see line 5 below).</p> <pre><code>import functools\ndef counted(f):\n@functools.wraps(f)\ndef wrapped(*args, **kwargs):\nwrapped.calls += 1\nreturn f(*args, **kwargs)\nwrapped.calls = 0\nreturn wrapped\n@counted\ndef f3(x, y, a):\n\"\"\"This functions returns the 'mixture' of 'x' and 'y',\n    'a' parts 'x' and (1 - a) 'y'\"\"\"  \nassert 0 &lt;= a &lt;= 1 # yes we can do that in Python\nreturn x * a + y * (1 - a)\nprint(f3.__doc__)\n</code></pre> <p><code>This functions returns the 'mixture' of 'x' and 'y', 'a' parts 'x' and (1 - a) 'y'</code></p>"},{"location":"part_VI_various/#context-managers","title":"Context Managers","text":"<p>When we open a file for reading or for manipulation, we probably want to close the file when done with it. There are multiple reasons why to 'close' at the end. Maybe by keeping the file open, another program cannot access the file as we are \"holding\" it. Then, potentially some of our activity is still only cached and if we want it be reflected in the file, we have to 'flush' or to 'close' the file. At any case an open file is associated with an OS resource or a handle, and it is a good idea to close it once we've done with using / modifying the file.</p> <pre><code>fh = open(\"my_file.txt\", \"w\")\nfh.write(\"E.T. phone home\")\nfh.close()\n</code></pre> <pre><code>!cat my_file.txt\n</code></pre> <p><code>E.T. phone home</code></p> <p>Above ('!cat ..') was done in a jupyter notebook and is a shell command-line execution.</p> <p>A better way to achieve above would be:</p> <pre><code>with open(\"my_file.txt\", \"a\") as fh:\nfh.write(\"\\nHere's my mobile\")\n</code></pre> <p>We \"entered\" the context manager of the file. When we \"exited\" (as of the indentation), the file was closed automatically. Note the usage of the with statement.</p> <p>If you have multiple files, for example you implement a filter that reads from one file and writes to another file, you can either indent even more, or also use commas in a single 'with' expression, as follows:</p> <pre><code>with open(\"my_file.txt\", \"r\") as fh, open(\"my_out_file.txt\", \"w\") as fh_w:\nfor line in fh:\nfh_w.write(line)\n</code></pre> <p>Context managers can may be available on additional \"resource\" kind objects. For example database connections. You can also create additional classes that support the context manager protocol and can be used in a 'with' statement.</p>"},{"location":"part_VI_various/#global-nonlocal","title":"global, nonlocal","text":"<p>Most of our variables should be local. What does it mean to be 'local'? Variables that are assigned in a function exist from the time they are defined till the end of the function's execution (when the function returns).</p> <pre><code>def main():\na = 3\nprint(a)\nif __name__ == \"__main__\":\nmain()\nprint(a)\n</code></pre> <pre><code>3\nTraceback (most recent call last):\n  File \"try2.py\", line 8, in &lt;module&gt;\n    print(a)\nNameError: name 'a' is not defined\n</code></pre> <p>If one defines a variable outside of the function then it will be available in the current namespace. It will become \"global\". This is not as terrible in Python as in other languages, as different namespaces do not share the globals among them. If one wants to access a global variable of another module, this needs to be done implicitly by prepending the name of the model and a dot, as, for example, in <code>my_model.tree_root</code>.</p> <p>Also in the example below, we see that the function does not assume its variable is the one in the outer context, but rather works with its own local variable.</p> <pre><code>a = 3\ndef f_a():\na = 5\nprint(a)\nf_a()\nprint(a)\n</code></pre> <pre><code>5\n3\n</code></pre> <p>It is good that the function f_a did not have a side effect of changing our \"global\" a.</p> <p>But what if we actually did mean to have it the same variable a? We need to make it implicit.</p> <pre><code>a = 3\ndef f_a():\nglobal a\na = 5\nprint(a)\nf_a()\nprint(a)\n</code></pre> <pre><code>5\n5\n</code></pre> <p>Let's see another example, in which we should actually use nonlocal rather than global.</p> <pre><code>a = 3\ndef f_a2():\na = 0\ndef f_a3():\na = a + 1\nf_a3()\nprint(a)\nf_a2()\nprint(a)\n</code></pre> <pre><code>---------------------------------------------------------------------------\nUnboundLocalError                         Traceback (most recent call last)\nCell In[31], line 10\n      7   f_a3()\n      8   print(a)\n---&gt; 10 f_a2()\n     11 print(a)\n\nCell In[31], line 7, in f_a2()\n      5 def f_a3():\n      6     a = a + 1\n----&gt; 7 f_a3()\n      8 print(a)\n\nCell In[31], line 6, in f_a2.&lt;locals&gt;.f_a3()\n      5 def f_a3():\n----&gt; 6     a = a + 1\n\nUnboundLocalError: local variable 'a' referenced before assignment\n</code></pre> <p>A possible solution is to implicitly declare a to be 'nonlocal':</p> <pre><code>a = 3\ndef f_a2():\na = 0\ndef f_a3():\nnonlocal a\na = a + 1\nf_a3()\nprint(a)\nf_a2()\nprint(a)\n</code></pre> <pre><code>1\n3\n</code></pre> <p>By saying 'nonlocal' one just instructs the runtime to look up in the stack for the variable that should already be available in an upper frame.</p>"},{"location":"part_VI_various/#type-hints","title":"Type Hints","text":"<p>Python is a dynamic language. Duck typing replaces type declarations and hard static enforcements.</p> <p>On the other hand, to build a more reliable software, and to help ourselves and future users, we may want here and there to implicitly \"hint\" the expected type or expected protocol of an argument and / or the type of the returned value.</p> <pre><code>from typing import List\ndef my_function(count: int) -&gt; List[str]:\nreturn ['Python'] * count\n</code></pre> <p>The \"hints\" add to the documentation. An IDE can use them to highlight potential issues. Tools such as mypy can verify that we pass the correct arguments.</p> <p>My suggestion is to add slowly more and more type hints wherever relevant. Does not need to happen all the once in all places in your code.</p> <p>Whatever the members of your team decide..</p>"},{"location":"part_VI_various/#json-xml-yaml","title":"JSON / XML / YAML","text":"<p>JavaScript Object Notation (JSON) is a very convinient textual hierarchical format to exchange data. Another useful and similar format Extensible Markup Language (XML). Both those format have great support in Python. A third format that is used often with Python is YAML.</p> <p>Those formats are useful for exchanging \"documents\" and for defining configurations. A Python code can quickly read a (small) JSON file into a dict. From there access to the different elements can be achieved with normal dict accessors.</p> <pre><code>import json\nd = dict(a = 3, b = {'c': \"hello\"})\nd_as_json = json.dumps(d)\nassert type(d_as_json) == str\ndel d\nd = json.loads(d_as_json)\nd['b']['c']\n</code></pre> <p><code>'hello'</code></p> <p>We can \"serialize\" a dict for example into a serie of characters that can be saved in a file, or be presented to a human being. It can be very useful in inter-process communication, as the content in HTTP requests, as a message, etc.</p> <p>All above formats can be, almost with no effort, converted from one format to the other. With Python this would be just by loading from the source format into a dict, and saving to the target format.</p> <pre><code>import yaml\nprint(yaml.dump(d))\n</code></pre> <pre><code>a: 3\nb:\n  c: hello\n</code></pre> <p>Interesting to know that objects in Python have an accessor attribute __dict__ that can be a good starting point for serialization.</p> <pre><code>class A:\ndef __init__(self, name: str, age: int):\nself.name = name\nself.age = age\ndef can_drive(self) -&gt; bool:\nreturn self.age &gt;= 18\nmy_a = A(\"Jaakov\", 16)\nmy_a.__dict__\n</code></pre> <pre><code>{'name': 'Jaakov', 'age': 16}\n</code></pre>"},{"location":"part_VI_various/#dataclass","title":"Dataclass","text":"<p>When we want to collect some pieces of information into a single variable, for example the x and the y coordinates of a point, we can use any of the built-in collections such as dict, tuple, list. To add more structure and to add specific functionality we can create a new class, say Point. We then need to decide if we want to allow / enforce settings the coordinates in the constructor, and whether those can be modified etc. A useful standard library provided utility decorator is dataclass. A lot of times, a dataclass is exactly what we need. Here is an example:</p> <pre><code>from dataclasses import dataclass\n@dataclass\nclass Point:\nx: int\ny: int\np1 = Point(1, 2)\np2 = Point(1, 4)\np1, p2\n</code></pre> <pre><code>(Point(x=1, y=2), Point(x=1, y=4))\n</code></pre> <p>Check this short (22:18) YouTube recording. This Is Why Python Data Classes Are Awesome (ArjanCodes)</p>"},{"location":"part_V_OO/","title":"Part V","text":"<p>We already mentioned that almost everything in Python is an object and has a type. We learn here to create new types, or also known as classes.</p> <pre><code>class State:\n\"\"\"\n  a state in the game, what cards each player has, etc.\n  \"\"\"\ndef __init__(self):\n# for the player I start with the sum rather than the cards to assure uniformity in the randomized start\nself.player_sum = random.randint(11, 21)\n# and so for the useful Ace\nself.player_useful_Ace = random.randint(0, 1) == 1 # boolean\nself.dealer_cards = [self._random_card(), self._random_card()]\ndef _random_card(self):\nreturn random.randint(1, 10) # 1 - Ace, 2, .. 10\ndef hits(self):\nnew_card = self._random_card()\nself.player_sum += new_card # note since we start with 11 we cannot add another ACE.\nif self.player_sum &gt; 21:\nif self.player_useful_Ace:\nself.player_sum -= 10\nself.player_useful_Ace = False\nreturn new_card\ndef stick(self):                    \nreturn self._dealers_turn()\n</code></pre> <p>Above is taken from a Black Jack implementation. When we need a new \"State\" for a game, we call it, as an example, as follows:</p> <pre><code>current_state = State()\nnew_card = current_state.hits()\n</code></pre> <p>The call in the example above to <code>State()</code> allocates space for the new object and calls the __init__ function on the new object. In the __init__ function we have the opportunity to initialize member variables. In addition to the __init__ we'll have usually additional functions. Most of which will have as a first parameter self which will be passes the relevant object. The name self is a convention rather than inforced. It means the object itself. The two expressions below are equivelant:</p> <pre><code>new_card = current_state.hits()\n# equivalent call\nnew_card = State.hits(current_state)\n</code></pre> <p>The initialization function __init__, as well as other functions, can of course have additional parameters.</p> <pre><code>class Car:\n\"\"\"\n  This class represents a car.\n  A car is needed in our system, for example with respect to the license plate registration.\n  \"\"\"\ndef __init__(self, license_plate):\nself.license_plate = license_plate\nself.level = None # till we learn otherwise\ndef indicate_in_the_parking(self, level):\nself.level = level\ndef indicate_out_of_the_parking(self):\nself.level = None\n</code></pre> <pre><code>my_car = Car(\"1234567\")\nmy_car.indicate_in_the_parking(3)\nCar.indicate_in_the_parking(my_car, 4) # you'll not see code like this usually\nmy_car.level\n</code></pre> <p>Which returns <code>4</code>. Note that it is a good practice to have all the member variables initialized in the __init__ even with None if we don't have something better.</p> <p>One can add functionality to an existing class, after all a class is an object by itself.</p> <pre><code>def wash(self, outside_only=True):\nprint(\"It is clean now.\")\nCar.wash = wash\nmy_car.wash()\n</code></pre> <p><code>It is clean now.</code></p> <p>If possible, avoid using this practice, just for your own sanity. But good to remember that it is an option.</p> <p>Inheritance is possible, here is a simple example:</p> <pre><code>class CompanyCar(Car):\n\"\"\"\n  A car that is owned by the company and is\n  currently allocated to one of our employees.\n  \"\"\"\ndef __init__(self, license_plate, employee):\nsuper().__init__(license_plate)\nself.employee = employee\ndef remind_APK(self):\npass\ncompany_cars = {\nemployee: CompanyCar(license_plate, employee)\nfor employee, license_plate in zip(\n[\"Jan S.\", \"Marrie W.\", \"Sara L.\"],\n[\"2222222\", \"2222223\", \"2222224\"]\n)\n}\ncompany_cars\n</code></pre> <pre><code>{'Jan S.': &lt;__main__.CompanyCar at 0x7fcd90087f40&gt;,\n 'Marrie W.': &lt;__main__.CompanyCar at 0x7fcd90087c40&gt;,\n 'Sara L.': &lt;__main__.CompanyCar at 0x7fcd90087a30&gt;}\n</code></pre> <p>Note that in the \"constructor\" of CompanyCar we have passed Car.</p> <p>For a better human readable representation add the __repr__ member function.</p> <pre><code>def company_car_repr(self):\nreturn f'car {self.license_plate} used by {self.employee}'\nCompanyCar.__repr__ = company_car_repr\ncompany_cars\n</code></pre> <pre><code>{'Jan S.': car 2222222 used by Jan S.,\n 'Marrie W.': car 2222223 used by Marrie W.,\n 'Sara L.': car 2222224 used by Sara L.}\n</code></pre> <p>Make sure the representation of the object still represents the object as this may be used for hashing etc. With above implementation, if you change the current employee using the car, you may not find the car object in a dict if you previously added it there as a key with the previous user.</p> <p>There are other useful Dunder (Double Under) \"magic\" methods in Python that are worth to know. For example __str__ that is used when converting an object to a string, ex. in <code>print(f'my object=\"{obj}\"')</code>. My intuition was to introduce __str__ yet to get above it turns out that one needs actually __repr__. When __repr__ is implemented while __str__ is not, __repr__ seems to be a fallback for example in f-strings.</p> <pre><code>def company_car_str(self):\nreturn f'car {self.license_plate} used by {self.employee}'\nCompanyCar.__str__ = company_car_str\ndef company_car_repr(self):\nreturn f'REPR car {self.license_plate} used by {self.employee}'\nCompanyCar.__repr__ = company_car_repr\nf'--&gt;{company_cars[\"Jan S.\"]}'\n</code></pre> <p><code>'--&gt;car 2222222 used by Jan S.'</code></p> <p>Yet if we 'del' __str__ we get:</p> <pre><code>del CompanyCar.__str__\nf'--&gt;{company_cars[\"Jan S.\"]}'\n</code></pre> <p><code>'--&gt;REPR car 2222222 used by Jan S.'</code></p> <p>With above we've inherited functionality from Car also to our CompanyCars.</p> <pre><code>company_cars['Jan S.'].wash()\n</code></pre> <p><code>it is clean now</code></p> <p>Object Oriented Programming (OOP) is very useful and definetly worth learning. For example with Polymorphism one can loop for example over a list of \"communication channels\", and \"send\" a message through all of those. The implementation of the \"emails\" instance will possibly be different from the \"SMS\" one, yet the interface of \"send\" is the same.</p> <p>While OOP brings a lot of capabilities there are issues that we should be careful with, such as multiple inheritance. When a class inherits from multiple classes, and there are conflicts, what takes precedence? How does everything work togther. There is a concept of Mixins that are regular Python classes, yet are meant to be self contained, used by inheritance just to add functionality, avoiding adding member variables, so less issues with multiple inheritance.</p> <p>A side note (a possible repetitive suggestion). Use object oriented as needed, yet prefer a simple existing class / container if such exists and does the work reasonably.</p> <p>Next I'm going to bring a nice example of the power of OOP when used in combination with functional programming.</p> <pre><code>from itertools import permutations\nclass MyClass:\ndef __init__(self, a, b):\nself.a = a\nself.b = b\ndef __repr__(self):\nreturn f'({self.a}, {self.b})'\ndef cmp(self, other):\n\"\"\"\n        This function returns 1 when this object strictly dominates the other.\n        It returns -1 when the other object strictly dominates this one.\n        Otherwise it returns 0.\n        \"\"\"\nif (\n(self.a &gt; other.a and self.b &gt;= other.b) or\n(self.a &gt;= other.a and self.b &gt; other.b)\n):\nreturn 1\nelif (\n(self.a &lt; other.a and self.b &lt;= other.b) or\n(self.a &lt;= other.a and self.b &lt; other.b)\n):\nreturn -1\nelse:\nreturn 0\nobjs = [\nMyClass(2, 3),\nMyClass(1, 2),\nMyClass(3, 1),\n]\nfor obj1, obj2 in permutations(objs, 2):\nprint(f'{obj1=}, {obj2=}, cmp={obj1.cmp(obj2)}')\n</code></pre> <pre><code>obj1=(2, 3), obj2=(1, 2), cmp=1\nobj1=(2, 3), obj2=(3, 1), cmp=0\nobj1=(1, 2), obj2=(2, 3), cmp=-1\nobj1=(1, 2), obj2=(3, 1), cmp=0\nobj1=(3, 1), obj2=(2, 3), cmp=0\nobj1=(3, 1), obj2=(1, 2), cmp=0\n</code></pre> <p>Makes sense? Now let's try to sort the list.</p> <pre><code>sorted(objs)\n</code></pre> <pre><code>---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[70], line 1\n----&gt; 1 sorted(objs)\n\nTypeError: '&lt;' not supported between instances of 'MyClass' and 'MyClass'\n</code></pre> <p>That's a pitty. We have a (partial) order already, why can't use use it for sorting? Let's try to use cmp.</p> <pre><code>def use_cmp(a, b):\nreturn a.cmp(b) &lt; 0\nsorted(objs, key=use_cmp)\n</code></pre> <pre><code>---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[74], line 1\n----&gt; 1 sorted(objs, key=use_cmp)\n\nTypeError: use_cmp() missing 1 required positional argument: 'b'\n</code></pre> <p>'key' is expecting a function with one parameter; an object. Then sorted calls this function to obtain the \"key\" which is then used to compare with the \"key\"s of the other objects. What should we do? Give up and add the '&lt;' operator to MyClass?</p> <p>Idea: we'll return an object as the \"key\". The \"key\" object shall keep track of the original object, and shall delegate to the original object's cmp when the '&lt;' is needed.</p> <pre><code>class Helper:\n\"\"\"\n    Enables '&lt;' from 'cmp'.\n    \"\"\"\ndef __init__(self, obj):\nself.obj = obj\ndef __lt__(self, other):\nreturn self.obj.cmp(other.obj) &lt; 0\nsorted(objs, key=Helper)\n</code></pre> <p><code>[(1, 2), (2, 3), (3, 1)]</code></p> <p>We probably could have implemented __lt__ directly in MyClass yet this would have kill the story. In functools you can find cmp_to_key that does exacly what we've just done (<code>from functools import cmp_to_key</code>).</p>"},{"location":"part_V_OO/#exercise","title":"Exercise","text":"<p>Are you familier with the game \"Animals\"? One person picks an animal (in his head). The other person (this will be the computer in this example), tries to guess the animal. The computer asks questions such as \"Does it live in water?\". The human answers with \"yes\" or \"no\".</p> <p>When the computer wants to guess, it asks for example: \"Is it a dog?\". If the computer was right, great. Otherwise, the computer asks three questions as follows:</p> <ul> <li>What was your animal? (ex. a cat)</li> <li>Can you give me a question that helps to tell between a cat and a dog? (ex. Does it barks?)</li> <li>And what would be the answer for a cat? (ex. no)</li> </ul> <p>Then the game continues. The computer get's smarter and smarter, by keeping trace of the possible animals and the questions that help to tell among those.</p> <p>A possible approach can be to create for the computer a \"tree\". A \"node\" in the tree is either a question, or an animal. A question leads to two subtrees, the one if the user's answer was \"no\" and another if the user's answer was \"yes\". An animal is a leaf node.</p> <p>Implement this game, potentially with a few classes such as \"TreeNode\", \"Animal\", \"Question\". The following may be handy.</p> <pre><code>a = input(\"enter you name\")\na\n</code></pre> <p>I have entered 'Oren' and indeed that was the content of a as a str.</p>"},{"location":"part_X_flask/","title":"Part X","text":"<p>Flask</p>"}]}